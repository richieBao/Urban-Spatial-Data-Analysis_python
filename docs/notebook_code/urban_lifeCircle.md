> Created on Wed Mar 27 20/33/48 2019 @author: Richie Bao-caDesignè®¾è®¡(cadesign.cn) __+updated on Wed Nov 25 23/31/32 2020 by Richie Bao

## 1.åŸå¸‚ç”Ÿæ´»åœˆï¼ŒDBSCANè¿ç»­è·ç¦»èšç±»ï¼Œå¡æ–¹åˆ†å¸ƒåŠç‹¬ç«‹æ€§æ£€éªŒï¼Œåæ–¹å·®ä¼°è®¡ï¼Œä¿¡æ¯ç†µä¸å‡è¡¡åº¦
æ¯”å°”Â·å¸Œåˆ©å°”æå‡ºâ€œç©ºé—´â€æ˜¯ç‰©è´¨å½¢æ€å’Œç¤¾ä¼šç»æµæ´»åŠ¨ç›¸äº’ä½œç”¨çš„åª’ä»‹ç‰©ï¼šç¤¾ä¼šç»æµæ´»åŠ¨ä¸ä»…å…·æœ‰ç©ºé—´æ€§ï¼Œå³ç¤¾ä¼šç»æµæ´»åŠ¨çš„å±•å¼€ä¾èµ–å…¶åœ¨ç©ºé—´ä¸Šçš„åˆ†å¸ƒï¼Œè€Œä¸”å®ƒä»¬çš„ç©ºé—´ç»„ç»‡å½¢å¼å—åˆ¶äºç©ºé—´è‡ªèº«çš„è§„å¾‹ã€‚å‡¯æ–‡Â·æ—å¥‡è®¤ä¸ºç‰©è´¨ç¯å¢ƒçš„å˜åŒ–å¯¹ç¤¾ä¼šåªæœ‰å¾®å°çš„å½±å“ï¼Œæ­£å¦‚ç¤¾ä¼šå˜é©ï¼ˆå³ä½¿æ˜¯é©å‘½ï¼‰å¯¹åŸå¸‚ç©ºé—´ä¹Ÿåªäº§ç”Ÿéç›´æ¥çš„å½±å“ä¸€æ ·ã€‚ç¤¾ä¼šç»“æ„å’Œç‰©è´¨ç©ºé—´å½¢æ€ä¹‹é—´æœ‰ç€å†…åœ¨çš„å…³ç³»ï¼Œå®ƒä»¬é€šè¿‡å…¶ä¸­çš„å˜é‡é•¿æœŸåœ°ç›¸äº’ä½œç”¨ç€ï¼Œä¹Ÿå°±æ˜¯é€šè¿‡äººçš„è¡ŒåŠ¨ä¸æ€åº¦ç›¸äº’ä½œç”¨ç€ã€‚åŸå¸‚çš„ç‰©è´¨ç©ºé—´å½¢æ€å’Œç¤¾ä¼šè¡Œä¸ºçš„å‘å±•æ˜¯å½¼æ­¤ç›¸äº’ä¾èµ–ï¼Œé•¿æœŸæ¸è¿›å¼ã€å°è§„æ¨¡å˜åŒ–ã€æ— åºçš„ï¼Œé€æ¸çš„è°ƒæ•´ã€ä¼˜åŒ–ç§¯ç´¯çš„ç»“æœã€‚

åœ¨ç¤¾ä¼šç»æµæ´»åŠ¨æ–¹é¢ï¼Œæ—¥æœ¬åœ¨ã€Šå†œæ‘ç”Ÿæ´»ç¯å¢ƒæ•´å¤‡è®¡åˆ’ã€‹ä¸­æå‡ºç”Ÿæ´»åœˆæ¦‚å¿µï¼Œå³æ˜¯æŒ‡æŸä¸€ç‰¹å®šåœ°ç†ã€ç¤¾ä¼šæ‘è½èŒƒå›´å†…äººä»¬æ—¥å¸¸ç”Ÿäº§ã€ç”Ÿæ´»çš„è¯¸å¤šæ´»åŠ¨åœ¨åœ°ç†å¹³é¢ä¸Šçš„åˆ†å¸ƒï¼Œä»¥ä¸€å®šäººå£çš„æ‘è½ã€ä¸€å®šè·ç¦»åœˆåŸŸä½œä¸ºåŸºç¡€ï¼Œå°†ç”Ÿæ´»åœˆæŒ‰ç…§æ‘è½-å¤§å­—-æ—§æ‘-å¸‚ç”ºæ‘-åœ°æ–¹éƒ½å¸‚åœˆè¿›è¡Œå±‚æ¬¡åˆ’åˆ†ã€‚è‡ªæ—¥æœ¬æå‡ºâ€œç”Ÿæ´»åœˆâ€æ¦‚å¿µä»¥æ¥ï¼Œå›½å†…å°±åŸå¸‚å‘å±•é€æ¸ä»å¤§å°ºåº¦çš„å®è§‚å™äº‹è½¬å‘å°å°ºåº¦çš„ç©ºé—´è°ƒæ•´ï¼Œå°†å±…æ°‘è§†ä¸ºå‡è´¨æ•´ä½“è½¬å‘å…³æ³¨ä¸åŒç¤¾ä¼šç¾¤ä½“çš„å¤šå…ƒéœ€æ±‚ï¼Œ é€æ¸å¼€å§‹å…³æ³¨åŸå¸‚ç”Ÿæ´»ç©ºé—´çš„æ„å»ºä¸å±…æ°‘ç”Ÿæ´»è´¨é‡çš„æå‡ã€‚å›½å†…çš„ç›¸å…³ç ”ç©¶ä¹Ÿåœ¨æŒç»­å±•å¼€ï¼Œæ¶‰åŠç”Ÿæ´»åœˆè§„åˆ’æ–¹æ³•å’Œç­–ç•¥ï¼Œç”Ÿæ´»åœˆçš„ç•Œå®šä¸æµ‹åº¦ï¼Œä»¥åŠå¤šä¸ªåŸå¸‚15åˆ†é’Ÿç”Ÿæ´»åœˆçš„åˆ’å®šä¸ç©ºé—´ä¼˜åŒ–ç­‰ã€‚å½“å‰çš„ç ”ç©¶å¤šä»¥è§„åˆ’ç†å¿µã€ç­–ç•¥å±…å¤šï¼Œå®šé‡åˆ†æä¸Šé€šå¸¸ä½äºä¸€ä¸ªå›ºå®šçš„æ—¶é—´è·ç¦»ä¸‹åˆ†æä¸€ä¸ªæˆ–å¤šä¸ªç›®æ ‡ä½ç½®èŒƒå›´ä¸‹çš„å±…æ°‘æ—¥å¸¸æ´»åŠ¨ï¼Œå¦‚å‡ºè¡Œè·¯å¾„å’ŒèŒƒå›´ã€ä»¥åŠæœåŠ¡è®¾æ–½çš„ç©ºé—´å¸ƒå±€ç»“æ„ç­‰ã€‚

ä»å•çº¯çš„å…³æ³¨ç‰©è´¨ç©ºé—´å¼€å§‹è½¬å‘è€ƒè™‘å…¶èƒŒåçš„ç¤¾ä¼šå±æ€§ï¼Œä»¥ç”Ÿæ´»åœˆä½œä¸ºåˆ‡å…¥ç‚¹æ¥è€ƒè™‘åŸå¸‚å¾®æ›´æ–°ç­‰æå‡å±…æ°‘ç”Ÿæ´»å“è´¨éœ€æ±‚çš„è§„åˆ’ç­–ç•¥ï¼Œä¸ºè¾¾åˆ°å…·ä½“è½å®çš„ç›®çš„ï¼Œæœ‰å¿…è¦é‡åŒ–ç”Ÿæ´»åœˆçš„ç©ºé—´åˆ†å¸ƒï¼Œç¤¾ä¼šå±æ€§çš„ç©ºé—´ç»“æ„ï¼Œä»¥åŠåŠ¨æ€çš„è¿ç»­æ—¶é—´è·ç¦»å±‚çº§å˜åŒ–å…³ç³»ï¼Œä»è€Œä½¿å¾—ç”Ÿæ´»åœˆè§„åˆ’ä¸­æ¶‰åŠåˆ°çš„äººæ–‡å…³æ€€ã€æ´»åŠ›ç¯å¢ƒä»¥åŠå®œäººçš„ç»¿è‰²ä¼‘é—²ç½‘ç»œç­‰å†…å®¹å¾—ä»¥åˆç†å¸ƒå±€ï¼Œè½å®åˆ°å‘æŒ¥å…¶æœ€å¤§ä»·å€¼çš„åŒºåŸŸå†…ã€‚

### 1.1 DBSCANï¼ŒAffinity Propagationï¼ˆAPï¼‰èšç±»ç®—æ³•
#### 1.1.1 DBSCANèšç±»ç®—æ³•

åœ¨èšç±»éƒ¨åˆ†ï¼Œè¯¦ç»†é˜è¿°äº†K-Meansç®—æ³•ï¼ŒK-Meansçš„å‚æ•°è¾“å…¥éœ€è¦ç¡®å®šåˆ†ç»„çš„æ•°é‡ï¼Œä½†æ˜¯è¦å°†å…´è¶£ç‚¹(points of interest,POI)æ•°æ®ç‚¹æŒ‰ç…§åœ°ç†ç©ºé—´åˆ†å¸ƒçš„è·ç¦»è¿›è¡Œèšç±»ï¼Œä¸èƒ½ç¡®å®šåˆ†ç»„çš„æ•°é‡ï¼Œåˆ™K-Meansç®—æ³•æ— æ³•å®ç°è¯¥éœ€æ±‚ã€‚åˆ†æPOIç©ºé—´åˆ†å¸ƒï¼Œåˆ™ä½¿ç”¨DBSCANï¼ˆDensity-Based Spatial Clustering of Applications with Noise.ï¼‰èšç±»åˆ†æã€‚è¯¥ç®—æ³•çš„å®ç°åœ¨Pythonç¨‹åºè®¾è®¡è¯­è¨€æœºå™¨å­¦ä¹ å¼€æºåº“scikit-learnçš„sklearn.clusterç±»ä¸­ï¼Œ`class sklearn.cluster.DBSCAN(eps,min_samples,*)`ï¼Œå…¶å…³é”®å‚æ•°è®¾ç½®ä¸­epsä¸ºè®¾ç½®é‡‡æ ·ç‚¹ä¹‹é—´çš„æœ€å¤§è·ç¦»ï¼›min_samplesä¸ºè®¾ç½®é‚»åŸŸæ ·æœ¬æ•°é‡ï¼ˆå«è‡ªèº«ï¼‰ã€‚

DBSCANå¯ä»¥è§£å†³K-Means,MeanShift,AffinityPropagation,MiniBatchKMeans,GaussianMixtureç­‰ç®—æ³•å¤±è´¥çš„éå‡¸é—®é¢˜ï¼ˆå‚çœ‹Sklearnå®˜ç½‘èšç±»éƒ¨åˆ†æä¾›çš„ä¸åŒèšç±»ç®—æ³•æ¯”è¾ƒä»£ç ç»“æœå›¾ç¤ºä¸­åŒå¼¯æœˆä¸€è¡Œï¼‰ã€‚DBSCANç®—æ³•çš„ä¸»è¦æ€æƒ³æ˜¯ï¼Œä¸€ä¸ªç°‡æ˜¯ä¸€ä¸ªè¢«ä½å¯†åº¦åŒºåŸŸåŒ…å›´çš„é«˜å¯†åº¦åŒºåŸŸï¼ˆå…¶å½¢çŠ¶æ²¡æœ‰é™åˆ¶ï¼‰ï¼Œä¸éœ€è¦é¢„å…ˆç»™å®šé¢„æœŸç°‡çš„æ•°é‡ã€‚è¿™ä¸ªè¿‡ç¨‹ä¸»è¦åŸºäºä¸€ä¸ªåº¦é‡å‡½æ•°ï¼ˆé€šå¸¸æ˜¯æ¬§æ°è·ç¦»ï¼Œå³epsï¼‰å’Œä¸€ä¸ªåŠå¾„ï¼ˆç†è§£ä¸ºé‚»åŸŸæ ·æœ¬çš„æ•°é‡ï¼‰ã€‚ç»™å®šä¸€ä¸ªæ ·æœ¬$x_{i} $ï¼Œè§‚å¯Ÿå…¶å‘¨è¾¹æ ·æœ¬ï¼Œå¦‚æœå®ƒè¢«è‡³å°‘$n_{min}$ä¸ªç‚¹åŒ…å›´ï¼Œåˆ™å…¶æˆä¸ºä¸€ä¸ªæ ¸å¿ƒç‚¹ï¼š$N(d( \overline{ x_{i} },\overline{ x_{j} } ) \leq  \epsilon ) \geq  n_{min} $ã€‚å¦‚æœ$d( \overline{ x_{i} },\overline{ x_{j} } ) \leq  \epsilon$ï¼Œåˆ™ä¸€ä¸ªæ ·æœ¬$ x_{j}$è¢«å®šä¹‰ä¸ºæ¥è¿‘æ ¸å¿ƒç‚¹$ x_{i}$ã€‚ä»¥æ­¤ç±»æ¨ï¼Œå¯¹äºä¸€ä¸ªå¯å½¢æˆç°‡çš„ç‚¹çš„åºåˆ—ï¼Œå¦‚æœ$x_{i}  \mapsto x_{i+1}  \mapsto  \ldots  \mapsto x_{j} $ï¼Œå„ä¸ªç‚¹é€ä¸€è¿ç»­é è¿‘ï¼Œåˆ™$x_{i} $å’Œ$x_{i} $è¢«è®¤ä¸ºæ˜¯å¯è¾¾çš„ï¼Œå³åŒ…å«åœ¨åŒä¸€ç°‡ä¸­ã€‚è¿›ä¸€æ­¥è®²ï¼Œå¦‚æœç»™å®šä¸€ä¸ªæ ·æœ¬$x_{k} $ï¼Œå¦‚æœ$x_{i} $å’Œ$x_{j} $éƒ½é è¿‘$x_{k} $ï¼Œåˆ™å®ƒä»¬æ˜¯å¯è¾¾çš„ï¼Œç´§å¯†é è¿‘çš„ã€‚å¦‚æœå¯¹äºæ‰€æœ‰æ ·æœ¬ä¸æ»¡è¶³ä¸Šè¿°è¦æ±‚åˆ™è®¤å®šä¸ºæ˜¯å™ªéŸ³ã€‚

å¯¹äºæ»¡è¶³è·ç¦»(eps)è¦æ±‚æ²¡æœ‰å‡ ä½•ç»“æ„é™åˆ¶çš„æ ·æœ¬ç‚¹å½’ä¸ºä¸€ä¸ªç°‡ï¼ŒåŒæ—¶ï¼Œå¦‚æœä¸´è¿‘çš„ç°‡é è¿‘è¿™ä¸ªç°‡ï¼Œæœ‰æ ·æœ¬æ»¡è¶³è·ç¦»è¦æ±‚ï¼Œåˆ™è¿™ä¸¤ä¸ªç°‡å¯ä»¥åˆå¹¶ä¸ºä¸€ä¸ªç°‡ï¼Œå¦åˆ™æ˜¯æ‹“æ‰‘åˆ†ç¦»çš„ã€‚å½“æ‰«æå®Œæ‰€æœ‰åŒºåŸŸåï¼Œåœ¨æ‰€æœ‰ç°‡ä¹‹é—´ä¹Ÿæœ‰å¯èƒ½æœ‰å•ç‹¬çš„ç‚¹ï¼Œå³å™ªéŸ³ç‚¹ï¼Œä¸èƒ½æ»¡è¶³è·ç¦»è¦æ±‚ä¸‹åˆ’åˆ†åˆ°ä»»ä½•ç°‡ä¸­ã€‚

æ¯”è¾ƒDBSCANå’ŒK-Meansç®—æ³•èšç±»éå‡¸å‡ ä½•ç»“æ„çš„æ•°æ®é›†ï¼ŒDBSCANå…·æœ‰è¾ƒå¥½çš„è¡¨ç°ã€‚

>  å‚è€ƒæ–‡çŒ®</br>
> 1. Giuseppe Bonaccorso.Mastering Machine Learning Algorithms: Expert techniques for implementing popular machine learning algorithms, fine-tuning your models, and understanding how they work[M].Birmingham:Packt Publishing.January, 2020.


```python
from sklearn.datasets import make_moons
from sklearn import cluster
import matplotlib.pyplot as plt
import numpy as np

nb_samples=1000
X,y=make_moons(n_samples=nb_samples, noise=0.05)

fig, axs=plt.subplots(1,3,figsize=(26/2,8/2))
axs[0].scatter(X[:, 0], X[:, 1])

#K-Meansèšç±»
clustering_KMeans=cluster.KMeans(n_clusters=2).fit(X)
pred_KMeans=clustering_KMeans.predict(X)
axs[1].scatter(X[:, 0], X[:, 1],c=pred_KMeans)

#DBSCANèšç±»
clustering_DBSCAN=cluster.DBSCAN(eps=0.3,min_samples=20).fit(X)
pred_DBSCAN=clustering_DBSCAN.labels_.astype(np.int)
axs[2].scatter(X[:, 0], X[:, 1],c=pred_DBSCAN)

plt.show()
```


    
<a href=""><img src="./imgs/16_02.png" height="auto" width="auto" title="caDesign"></a>
    


#### 1.1.2 Affinity Propagationï¼ˆAPï¼‰èšç±»ç®—æ³•
APèšç±»é€‚åˆé«˜ç»´ã€å¤šç±»æ•°æ®å¿«é€Ÿèšç±»ï¼Œèšç±»æ€§èƒ½å’Œæ•ˆç‡æœ‰å¤§å¹…åº¦æå‡ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯å°†å…¨éƒ¨æ ·æœ¬çœ‹ä½œç½‘ç»œçš„èŠ‚ç‚¹ï¼Œé€šè¿‡ç½‘ç»œä¸­å„è¾¹çš„æ¶ˆæ¯ä¼ é€’è®¡ç®—å„æ ·æœ¬çš„èšç±»ä¸­å¿ƒã€‚ä¼ é€’çš„æ¶ˆæ¯åŒ…æ‹¬å¸å¼•åº¦ï¼ˆresponsibilityï¼‰å’Œå½’å±åº¦ï¼ˆavailabilityï¼‰ã€‚APç®—æ³•é€šè¿‡è¿­ä»£è¿‡ç¨‹ä¸æ–­æ›´æ–°æ¯ä¸€ä¸ªç‚¹çš„å¸å¼•åº¦å’Œå½’å±åº¦ï¼Œç›´åˆ°äº§ç”Ÿ$m$ä¸ªé«˜è´¨é‡çš„èšç±»ä¸­å¿ƒï¼ˆExemplaï¼‰ï¼ŒåŒæ—¶å°†å…¶ä½™çš„æ•°æ®ç‚¹åˆ†é…åˆ°ç›¸åº”çš„èšç±»ä¸­ã€‚APç®—æ³•ä¸éœ€æŒ‡å®šèšç±»æ•°é‡ï¼Œç›¸å¯¹å…¶å®ƒç®—æ³•ï¼Œå…¶è¯¯å·®å¹³æ–¹å’Œç›¸å¯¹è¾ƒä½ã€‚åœ¨POIçš„ç©ºé—´ç»“æ„åˆ†æä¸­ï¼Œä½¿ç”¨è¯¥ç®—æ³•èšç±»è¡Œä¸šåˆ—è¡¨ä¸DBSCANèšç±»ç°‡çš„åˆ—è”è¡¨ï¼Œä»è€Œèƒ½å¤Ÿå¾—å‡ºè¡Œä¸šç±»ä¹‹é—´çš„ç›¸å…³æ€§ã€‚

### 1.2 å¡æ–¹åˆ†å¸ƒä¸ç‹¬ç«‹æ€§æ£€éªŒ
#### 1.2.1 å¡æ–¹åˆ†å¸ƒ(Chi-Square Distribution,Ï‡Â²-distribution)
è‹¥kä¸ªéšæœºå˜é‡$Z_{1} , \ldots  \ldots ,Z_{k}$ï¼Œæ˜¯ç›¸äº’ç‹¬ç«‹ï¼Œç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒçš„éšæœºå˜é‡ï¼ˆæ•°å­¦æœŸæœ›ä¸º0ï¼Œæ–¹å·®ä¸º1ï¼‰ï¼Œåˆ™éšæœºå˜é‡$Z$çš„å¹³æ–¹å’Œ$X= \sum_{i=1}^k   x_{i} ^{2}$è¢«ç§°ä¸ºæœä»è‡ªç”±åº¦ä¸º$k$çš„å¡æ–¹åˆ†å¸ƒï¼Œè®°ä½œ$X \sim  x^{2} (k)$æˆ–$X \sim   x_{k} ^{2} $ã€‚å¡æ–¹åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆå³è®¡ç®—å¡æ–¹åˆ†å¸ƒæ›²çº¿çš„å…¬å¼ï¼‰ä¸ºï¼š$f_{k} (x)= \frac{  \frac{1}{2} ^{ \frac{k}{2} } }{ \Gamma ( \frac{k}{2} )}  x^{ \frac{k}{2}-1 } e^{ \frac{-x}{2} }  $ï¼Œå…¶ä¸­$x \geq 0$ï¼Œå½“$x  \leq 0$æ—¶$f_{k} (x)=0$ã€‚$\Gamma $ä»£è¡¨Gammaå‡½æ•°ã€‚åœ¨pythonä¸­ç»˜åˆ¶å¡æ–¹åˆ†å¸ƒï¼Œä»æ—§ä¸æ­£æ€åˆ†å¸ƒã€tåˆ†å¸ƒä¸€æ ·ï¼Œç›´æ¥ç”±SciPyåº“å®Œæˆã€‚

å› ä¸ºå¡æ–¹åˆ†å¸ƒè¡¨è¿°çš„æ˜¯å¤šä¸ªäº‹ä»¶ï¼ˆéšæœºå˜é‡ï¼‰çš„æœºç‡ï¼Œæ¯ä¸ªäº‹ä»¶ç¬¦åˆæ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œè€Œæ ‡å‡†æ­£æ€åˆ†å¸ƒè¡¨ä¸ºè®°å½•å¯¹åº”æ¨ªè½´åˆ»åº¦çš„æœºç‡è¡¨ï¼Œå¡æ–¹åˆ†å¸ƒè¡¨åˆ™æ˜¯è®°å½•å¯¹åº”å‡ ç‡çš„æ¨ªè½´åˆ»åº¦è¡¨ã€‚

å¯¹äºå¡æ–¹åˆ†å¸ƒçš„ç†è§£ï¼Œå¯ä»¥ç»“åˆæ¯”è¾ƒå‡å€¼æŠ½æ ·åˆ†å¸ƒï¼ˆäºæ ‡å‡†è¯¯éƒ¨åˆ†é˜è¿°ï¼‰ï¼ŒäºŒè€…å…·æœ‰ç±»ä¼¼çš„é€»è¾‘ã€‚å³å¯ä»¥è¡¨è¿°ä¸ºä»åŒä¸€æ€»ä½“ä¸­æŠ½å–ç›¸åŒå®¹é‡æ ·æœ¬å¹³æ–¹å’Œçš„åˆ†å¸ƒï¼Œå‡è®¾ä»æœä»å¹³å‡å€¼ä¸º30ï¼Œæ ‡å‡†å·®ä¸º5çš„æ­£æ€åˆ†å¸ƒä¸­ï¼Œéšæœºæå–2000ä¸ªæ ·æœ¬ï¼ˆäº‹ä»¶ï¼Œæˆ–éšæœºå˜é‡ï¼Œå³$Z_{k}$ï¼‰ï¼Œå„ä¸ªæ ·æœ¬çš„å®¹é‡ä¸º1000ï¼Œè®¡ç®—æ¯ä¸€æ ·æœ¬çš„å¹³æ–¹å’Œï¼Œè§‚å¯Ÿè¿™2000ä¸ªæ ·æœ¬çš„å¡æ–¹åˆ†å¸ƒæƒ…å†µã€‚ä»ä¸‹è¿°å®éªŒæ‰“å°ç»“æœæ¥çœ‹ï¼Œ$x^{2}$è¶‹è¿‘æœä»è‡ªç”±åº¦ä¸º$(2000-1)$çš„$x^{2}$åˆ†å¸ƒã€‚å³å¯ä»¥é€šè¿‡ä¸€ä¸ªæ£€éªŒç»Ÿè®¡é‡ï¼ˆå¹³æ–¹å’Œï¼‰æ¥æ¯”è¾ƒæœŸæœ›ç»“æœå’Œå®é™…ç»“æœä¹‹é—´çš„å·®åˆ«ï¼Œç„¶åå¾—å‡ºè§‚å¯Ÿé¢‘æ•°æå€¼çš„å‘ç”Ÿæ¦‚ç‡ã€‚å› æ­¤ä»¥ç‰¹å®šæ¦‚ç‡åˆ†å¸ƒä¸ºæŸç§æƒ…å†µå»ºæ¨¡æ—¶ï¼Œäº‹ä»¶é•¿æœŸç»“æœè¾ƒä¸ºç¨³å®šï¼Œèƒ½å¤Ÿæ¸…æ™°è¿›è¡ŒæŠŠæ¡ã€‚ä½†æ˜¯å¦‚æœæœŸæœ›ä¸äº‹å®å­˜åœ¨å·®å¼‚æ—¶ï¼Œåˆ™å¯ä»¥åº”ç”¨å¡æ–¹åˆ†å¸ƒåˆ¤æ–­åå·®æ˜¯æ­£å¸¸çš„å°å¹…åº¦æ³¢åŠ¨è¿˜æ˜¯å»ºæ¨¡ä¸Šçš„é”™è¯¯ã€‚ä¸€æ˜¯ï¼Œå¯ä»¥æ£€éªŒä¸€ç»„ç»™å®šæ•°æ®ä¸æŒ‡å®šåˆ†å¸ƒçš„å»åˆç¨‹åº¦ï¼›äºŒæ˜¯ï¼Œå¯ä»¥æ£€éªŒä¸¤ä¸ªå˜é‡çš„ç‹¬ç«‹æ€§ï¼Œå³å˜é‡ä¹‹é—´æ˜¯å¦å­˜åœ¨æŸç§å…³ç³»ã€‚

* $\Gamma $å‡½æ•°

åœ¨æ•°å­¦ä¸­ï¼Œ$\Gamma $å‡½æ•°ï¼Œä¹Ÿç§°ä¸ºä¼½é©¬å‡½æ•°(Gammaå‡½æ•°)ï¼Œæ˜¯é˜¶ä¹˜å‡½æ•°åœ¨å®æ•°ä¸å¤æ•°åŸŸä¸Šçš„æ‰©å±•ã€‚å¦‚æœ$n$ä¸ºæ­£æ•´æ•°ï¼Œåˆ™ï¼š$\Gamma (n)=(n-1)!$ï¼Œå³æ­£æ•´æ•°çš„é˜¶ä¹˜ï¼›å¯¹äºå®æ•°éƒ¨åˆ†ä¸ºæ­£çš„å¤æ•°$z$ï¼Œä¼½é©¬å‡½æ•°å®šä¹‰ä¸ºï¼š$\Gamma (z)= \int_0^ \infty   t^{z-1} e^{-t} dt$ã€‚å‘ç°$\Gamma $å‡½æ•°çš„èµ·å› æ˜¯æ•°åˆ—æ’å€¼é—®é¢˜ï¼Œå³æ‰¾åˆ°ä¸€ä¸ªå…‰æ»‘çš„æ›²çº¿è¿æ¥é‚£äº›ç”±$y=(x-1)!$æ‰€ç»™å®šçš„ç‚¹$(x,y)$ï¼Œå¹¶è¦æ±‚$x$ä¸ºæ­£æ•´æ•°ã€‚ä½†æ˜¯å¦‚æœ$x$ç”±æ­£æ•´æ•°æ‹“å±•åˆ°å®æ•°ï¼Œå³å¯ä»¥è®¡ç®—$2!,3!, \ldots ,$ï¼Œé‚£ä¹ˆæ˜¯å¦å¯ä»¥è®¡ç®—$2.5ï¼$ï¼Œå¹¶ç»˜åˆ¶$(n,n!)$çš„å¹³æ»‘æ›²çº¿ï¼Ÿè€Œ$\Gamma $å‡½æ•°æ­£æ˜¯å€Ÿç”±å¾®ç§¯åˆ†çš„ç§¯åˆ†ä¸æé™è¡¨è¾¾é˜¶ä¹˜ã€‚

ä¼½é©¬(Gamma)åˆ†å¸ƒï¼Œå‡è®¾$X_{1} ,X_{2}, \ldots ,X_{n}$ä¸ºè¿ç»­å‘ç”Ÿäº‹ä»¶çš„ç­‰å€™æ—¶é—´ï¼Œä¸”è¿™$n$æ¬¡ç­‰ä¾¯æ—¶é—´ä¸ºç‹¬ç«‹çš„ï¼Œé‚£ä¹ˆè¿™$n$æ­¤ç­‰å€™æ—¶é—´ä¹‹å’Œ$Y(Y=X_{1} ,X_{2}, \ldots ,X_{n})$æœä»ä¼½é©¬åˆ†å¸ƒï¼Œå³$Y \sim Gamma( \alpha , \beta )$,å…¶ä¸­$\alpha =n, \beta = \gamma $ï¼Œ$\alpha$æ˜¯ä¼½é©¬åˆ†å¸ƒä¸­çš„æ¯æ•°ï¼Œç§°ä¸ºå½¢çŠ¶å‚æ•°ï¼Œ$\beta$ä¸ºå°ºåº¦å‚æ•°ã€‚$\gamma$æ˜¯è¿ç»­å‘ç”Ÿäº‹ä»¶çš„å¹³å‡å‘ç”Ÿé¢‘ç‡ã€‚æŒ‡æ•°åˆ†å¸ƒæ˜¯ä¼½é©¬åˆ†å¸ƒ$\alpha=1$çš„ç‰¹æ®Šæƒ…å†µã€‚ 

ä»¤$X \sim  \Gamma ( \alpha , \beta )$ï¼Œä¸”$\lambda = \beta $ï¼ˆå³$X \sim  \Gamma ( \alpha ,  \gamma  )$ï¼‰ï¼Œåˆ™ä¼½é©¬åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ä¸ºï¼š$f(x)= \frac{ x^{a-1}  \gamma ^{a}   e^{- \gamma x} }{ \Gamma (a)} ,x>0$ï¼Œå…¶ä¸­ä¼½é©¬å‡½æ•°çš„ç‰¹å¾ä¸ºï¼š$\begin{cases}  \Gamma (a)=(a-1)! & if\: a\: is\:  \mathbb{Z}^{+} \\\Gamma (a)=(a-1) \Gamma (a-1) & if\: a\: is\:  \mathbb{R}^{+} \\\ \Gamma ( \frac{1}{2}= \sqrt{ \pi }  ) \end{cases} $



> å‚è€ƒæ–‡çŒ®</br>
> 1.Timothy C.Urdan.Statistics in Plain English(ç™½è¯ç»Ÿè®¡å­¦)[M].ä¸­å›½äººæ°‘å¤§å­¦å‡ºç‰ˆç¤¾.2013,12.ç¬¬3ç‰ˆ.</br>
2.(æ—¥)é«˜æ¡¥ ä¿¡è‘—,æ ªå¼ä¼šç¤¾TREND-PROæ¼«ç”»åˆ¶ä½œï¼Œé™ˆåˆšè¯‘.æ¼«ç”»ç»Ÿè®¡å­¦[M].ç§‘å­¦å‡ºç‰ˆç¤¾.åŒ—äº¬.</br>
3.Dawn Griffiths.Head First Statistics: A Brain-Friendly Guide[M].Sebastopol:O'Reilly Media.September, 2008 




```python
import numpy as np
from scipy import stats
import seaborn as sns
import math
sns.set()
mu,sigma=30,5
sample_size=1000
sample_square=np.array([np.square(np.random.normal(mu, sigma, sample_size)) for i in range(2000)]) #ä»æœä»å¹³å‡å€¼ä¸º30ï¼Œæ ‡å‡†å·®ä¸º5çš„æ­£æ€åˆ†å¸ƒä¸­ï¼Œéšæœºæå–2000ä¸ªæ ·æœ¬ï¼Œæ¯ä¸ªæ ·æœ¬å®¹é‡ä¸º1000çš„æ ·æœ¬ï¼Œå¹¶è®¡ç®—æ¯ä¸€æ ·æœ¬çš„å‡å€¼
bins=30
sns.distplot(sample_square,bins=bins) #æŸ¥çœ‹2000ä¸ªæ ·æœ¬å¹³æ–¹å’Œçš„åˆ†å¸ƒ
```

    C:\Users\richi\Anaconda3\envs\usda\lib\site-packages\seaborn\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).
      warnings.warn(msg, FutureWarning)
    




    <AxesSubplot:ylabel='Density'>




    
<a href=""><img src="./imgs/16_03.png" height="auto" width="auto" title="caDesign"></a>
    


ä½¿ç”¨SciPyåº“è®¡ç®—æ‰“å°å¡æ–¹åˆ†å¸ƒåŠä¼½é©¬åˆ†å¸ƒ


```python
import matplotlib.pyplot as plt
from scipy.stats import chi2
import numpy as np

fig, axs=plt.subplots(1,2,figsize=(18/1.5,8/1.5)) 

#A-å¡æ–¹åˆ†å¸ƒ
df=55
mean,var,skew,kurt=chi2.stats(df, moments='mvsk')
#æ‰“å°å¡æ–¹åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•° Display the probability density function (pdf)
x=np.linspace(chi2.ppf(0.01, df),chi2.ppf(0.99, df), 100)
axs[0].plot(x, chi2.pdf(x, df),'r-', lw=5, alpha=0.6, label='chi2 pdf_55')

df_lst=[20,30,40,80,100]
fmts=['b-','g-','y-','m-','c-']
for i in range(len(df_lst)):
    axs[0].plot(x, chi2.pdf(x, df_lst[i]),fmts[i], lw=3, alpha=0.6, label='chi2 pdf_%d'%df_lst[i])
    
#å›ºå®šåˆ†å¸ƒ Alternatively, freeze the distribution and display the frozen pdf
rv=chi2(df)
axs[0].plot(x, rv.pdf(x), 'k-', lw=2, label='frozen pdf_55')

vals=chi2.ppf([0.001, 0.5, 0.999], df)
print("Chi_2_Check accuracy of cdf and ppf:",np.allclose([0.001, 0.5, 0.999], chi2.cdf(vals, df)))

r=chi2.rvs(df, size=1000)
axs[0].hist(r, density=True, histtype='stepfilled', alpha=0.2)
axs[0].legend(loc='best', frameon=False)
               
#B-Gammaåˆ†å¸ƒ    
from scipy.stats import gamma
a=1.99323054838
mean_,var_,skew_,kurt_=gamma.stats(a, moments='mvsk')
#æ‰“å°Gammaåˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•° Display the probability density function (pdf):
x_= np.linspace(gamma.ppf(0.01, a),gamma.ppf(0.99, a), 100)
axs[1].plot(x_, gamma.pdf(x_, a),'r-', lw=5, alpha=0.6, label='gamma pdf')
#Alternatively, freeze the distribution and display the frozen pdf:
rv_= gamma(a)
axs[1].plot(x_, rv_.pdf(x_), 'k-', lw=2, label='frozen pdf')

vals = gamma.ppf([0.001, 0.5, 0.999], a)
print("Gamma_Check accuracy of cdf and ppf:",np.allclose([0.001, 0.5, 0.999], gamma.cdf(vals, a)))

r_=gamma.rvs(a, size=1000)
axs[1].hist(r_, density=True, histtype='stepfilled', alpha=0.2)
axs[1].legend(loc='best', frameon=False)

axs[0].set_title(r'Chi-Square Distribution', fontsize=15)
axs[1].set_title(r'Gamma Distribution', fontsize=15)
plt.show()               
```

    Chi_2_Check accuracy of cdf and ppf: True
    Gamma_Check accuracy of cdf and ppf: True
    


    
<a href=""><img src="./imgs/16_04.png" height="auto" width="auto" title="caDesign"></a>
    


#### 1.2.2 ï¼ˆå¡æ–¹ï¼‰ç‹¬ç«‹æ€§æ£€éªŒ
å¡æ–¹æ£€éªŒï¼ˆChi-Squared Testï¼Œæˆ– $x^{2}$ Testï¼‰,æ˜¯å‡è®¾æ£€éªŒçš„ä¸€ç§,ä¸€ç§éå‚æ•°å‡è®¾æ£€éªŒï¼Œä¸»è¦ç”¨äºç±»åˆ«/åˆ†ç±»å˜é‡ï¼ˆç±»åˆ«å˜é‡å°±æ˜¯å–å€¼ä¸ºç¦»æ•£å€¼çš„å˜é‡ï¼Œä¾‹å¦‚æ€§åˆ«å³ä¸ºä¸€ä¸ªç±»åˆ«å˜é‡ï¼Œæœ‰ç”·å¥³ä¸¤ç±»ï¼Œåˆæˆ–è€…å›½ç±ã€å­¦ç§‘ã€æ¤ç‰©ç­‰çš„ç±»åˆ«ç­‰ï¼‰ï¼Œåœ¨æ²¡æœ‰å…¶ä»–çš„é™åˆ¶æ¡ä»¶æˆ–è¯´æ˜æ—¶ï¼Œå¡æ–¹æ£€éªŒä¸€èˆ¬æŒ‡ä»£çš„æ˜¯çš®å°”æ£®å¡æ–¹(Pearson)æ£€éªŒã€‚1900å¹´ï¼ŒPearsonå‘è¡¨äº†è‘—åçš„$x^{2}$æ£€éªŒçš„è®ºæ–‡ï¼Œå‡è®¾å®éªŒä¸­ä»æ€»ä½“éšæœºå–æ ·å¾—åˆ°çš„$n$ä¸ªè§‚å¯Ÿå€¼è¢«åˆ’åˆ†ä¸º$k$ä¸ªäº’æ–¥çš„åˆ†ç±»ä¸­ï¼Œè¿™æ ·æ¯ä¸ªåˆ†ç±»éƒ½æœ‰ä¸€ä¸ªå¯¹åº”å®é™…çš„è§‚å¯Ÿæ¬¡æ•°ï¼ˆæˆ–è§‚æµ‹é¢‘æ•°ï¼Œobserved frequenciesï¼‰$ x_{i} (i=1,2, \ldots ,k)$ã€‚å¯¹å®éªŒä¸­å„ä¸ªè§‚å¯Ÿå€¼è½å…¥ç¬¬$i$ä¸ªåˆ†ç±»çš„æ¦‚ç‡$p_{i}$çš„åˆ†å¸ƒæå‡ºé›¶å‡è®¾ï¼Œè·å¾—å¯¹åº”æ‰€æœ‰ç¬¬$i$åˆ†ç±»çš„ç†è®ºæœŸæœ›æ¬¡æ•°(æˆ–é¢„æœŸé¢‘æ•°ï¼Œexpected frequencies)ä»¥åŠé™åˆ¶æ¡ä»¶ï¼Œ$\sum_{i=1}^k  p_{i}  =1,and \: \sum_{i=1}^k  m_{i} =\sum_{i=1}^k  x_{i} =n$ã€‚åœ¨ä¸Šè¿°é›¶å‡è®¾æˆç«‹ä»¥åŠ$n$è¶‹å‘$\infty $æ—¶ï¼Œä»¥ä¸‹ç»Ÿè®¡é‡çš„æé™åˆ†å¸ƒè¶‹å‘$x^{2}$åˆ†å¸ƒï¼Œ$X^{2} = \sum_{i=1}^k  \frac{ ( x_{i} - m_{i} )^{2} }{m_{i}}  =\sum_{i=1}^k  \frac{ x_{i} ^{2} }{m_{i}} -n$ã€‚$X^{2}$å€¼çš„è®¡ç®—å…¬å¼é€šå¸¸è¡¨ç¤ºä¸ºï¼š$X^{2} =  \sum ( \frac{ (O-E)^{2} }{E} )$ï¼Œå…¶ä¸­ï¼Œ$O$ä¸ºå„ä¸ªå•å…ƒæ ¼ï¼ˆå¯¹åˆ—è”è¡¨è€Œè¨€ï¼‰çš„è§‚æµ‹å€¼ï¼ˆè§‚æµ‹é¢‘æ•°ï¼‰ï¼Œ$E$ä¸ºå„ä¸ªå•å…ƒæ ¼çš„é¢„æœŸå€¼ï¼ˆé¢„æœŸé¢‘æ•°ï¼‰ã€‚é›¶å‡è®¾ä¸­æ‰€æœ‰åˆ†ç±»çš„ç†è®ºæœŸæœ›æ¬¡æ•°$m_{i}$å‡ä¸ºè¶³å¤Ÿå¤§ä¸”å·²çŸ¥çš„æƒ…å†µï¼ŒåŒæ—¶å‡è®¾å„åˆ†ç±»çš„å®é™…è§‚å¯Ÿæ¬¡æ•°$x_{i}$å‡æœä»æ­£æ€åˆ†å¸ƒï¼Œå¾—å‡ºæ ·æœ¬å®¹é‡$n$è¶³å¤Ÿå¤§æ—¶ï¼Œ$x^{2}$è¶‹è¿‘æœä»è‡ªç”±åº¦ä¸º$(k-1)$çš„$x^{2}$åˆ†å¸ƒã€‚

é€šå¸¸å°†ç”¨äºå¡æ–¹æ£€éªŒçš„æ•°æ®ä»¥è¡¨æ ¼çš„å½¢å¼ç»™å‡ºå¹¶ä¾æ®è¡¨æ ¼è¿›è¡Œè®¡ç®—ï¼Œè¿™ä¸ªè¡¨æ ¼å³ä¸ºåˆ—è”è¡¨(contingency tabel)ã€‚ä»¥*ç™½è¯ç»Ÿè®¡å­¦*æ€§åˆ«ä¸ä¸“ä¸šçš„ä¿®è®¢æ•°æ®ä¸ºä¾‹ï¼Œ


| æ€§åˆ«/ä¸“ä¸š      | å¿ƒç†å­¦ | è‹±è¯­     |ç”Ÿç‰©å­¦ |è¡Œåˆè®¡     |
| :---        |    :----:   |          ---: | ---: |---: |
| ç”·ç”Ÿ      | 35       | 50  |15|100|
| å¥³ç”Ÿ      | 30        | 25      |45|100|
| åˆ—åˆè®¡      | 65        | 75      |60|200|

åˆ©ç”¨è¡¨æ ¼æ¯ä¸€å•å…ƒæ ¼ä¸­çš„è§‚æµ‹é¢‘æ•°ï¼Œä»¥åŠè¡Œã€åˆ—å’Œæ•´ä¸ªæ ·æœ¬çš„åˆè®¡é¢‘æ•°ï¼Œè®¡ç®—æ¯ä¸ªå•å…ƒæ ¼çš„é¢„æœŸé¢‘æ•°ã€‚ç”·å¥³ä¸¤è¡Œä¸­æ¯ä¸€å•å…ƒæ ¼çš„é¢„æœŸå€¼éƒ½ç›¸ç­‰ï¼Œæ˜¯å› ä¸ºæ ·æœ¬ä¸­çš„ç”·å¥³ç”Ÿäººæ•°ç›¸ç­‰ã€‚å¹¶æ ¹æ®ä¸Šè¿°çš„$X^{2}$å€¼çš„è®¡ç®—å…¬å¼ï¼Œè®¡ç®—$X^{2}$ï¼Œå…¶å’Œä¸ºï¼š0.19+0.19+4.17+4.17+7.5+7.5=23.72ã€‚

| æ€§åˆ«/ä¸“ä¸š      | å¿ƒç†å­¦ | è‹±è¯­     |ç”Ÿç‰©å­¦ |
| :---        |    :----  |          :---| :--- |
| ç”·ç”Ÿ      |    è§‚æµ‹é¢‘æ•°ï¼š35 </br>é¢„æœŸé¢‘æ•°ï¼š$\frac{100 \times 65}{200} =32.5$ </br>$x^{2}$å€¼ï¼š$ \frac{ (35-32.5)^{2} }{32.5} =0.19$   |è§‚æµ‹é¢‘æ•°ï¼š50 </br> é¢„æœŸé¢‘æ•°:$\frac{100 \times 75}{200} =37.5$</br> $x^{2}$å€¼ï¼š$ \frac{ (50-37.5)^{2} }{37.5} =4.17$ |è§‚æµ‹é¢‘æ•°ï¼š15 </br> é¢„æœŸé¢‘æ•°: $\frac{100 \times 60}{200} =30$</br> $x^{2}$å€¼ï¼š$ \frac{ (15-30)^{2} }{30} =7.5$ |
| å¥³ç”Ÿ      | è§‚æµ‹é¢‘æ•°ï¼š30 </br>é¢„æœŸé¢‘æ•° $\frac{100 \times 65}{200} =32.5$ </br>$x^{2}$å€¼ï¼š$ \frac{ (30-32.5)^{2} }{32.5} =0.19$    |è§‚æµ‹é¢‘æ•°ï¼š25 </br> é¢„æœŸé¢‘æ•°:  $\frac{100 \times 75}{200} =37.5$ </br>$x^{2}$å€¼ï¼š$ \frac{ (25-37.5)^{2} }{37.5} =4.17$ | è§‚æµ‹é¢‘æ•°ï¼š45 </br> é¢„æœŸé¢‘æ•°: $\frac{100 \times 60}{200} =30$</br>$x^{2}$å€¼ï¼š$ \frac{ (45-30)^{2} }{30} =7.5$ |

æ³¨æ„åˆ°$x^{2}$å€¼è¾ƒå¤§æ˜¯å› ä¸ºç”·å¥³ç”Ÿåœ¨é€‰æ‹©è‹±è¯­æˆ–ç”Ÿç‰©ä¸“ä¸šæ—¶å­˜åœ¨ç›¸å¯¹è¾ƒå¤§çš„å·®å¼‚ã€‚è€Œå¿ƒç†å­¦ä¸“ä¸šçš„è§‚æµ‹å€¼å’Œé¢„æœŸå€¼ä¹‹å·®ç›¸å¯¹è¾ƒå°ï¼Œå¯¹æ•´ä½“$x^{2}$å€¼çš„è´¡çŒ®ä¸å¤§ã€‚è·å¾—è§‚æµ‹çš„$x^{2}$å€¼ï¼Œåˆ™éœ€è¦æŸ¥è¡¨ï¼ˆæˆ–ç¨‹åºï¼‰æŸ¥æ‰¾ä¸´ç•Œ$x^{2}$å€¼ï¼Œå…¶è‡ªç”±åº¦$df=(R-1)(C-1)=(2-1)\times(3-1)=2$ï¼Œä½¿ç”¨SciPyçš„`chi2.ppf(q=1-0.05,df=2)`è®¡ç®—å¯å¾—0.05çš„$\alpha $æ°´å¹³ï¼Œè‡ªç”±åº¦ä¸º2çš„æ¡ä»¶ä¸‹ä¸´ç•Œ$x^{2}$å€¼ä¸º5.99ï¼Œè€Œè§‚æµ‹çš„$x^{2}$å€¼ä¸º23.72ï¼Œæ‰€ä»¥å¯ä»¥å¾—å‡ºç»“è®ºï¼Œç”·å¥³ç”Ÿåœ¨ä¸“ä¸šé€‰æ‹©ä¸Šå­˜åœ¨ç»Ÿè®¡æ˜¾è‘—çš„å·®å¼‚ã€‚è€Œå› ä¸ºè§‚æµ‹çš„$x^{2}$å€¼è¶³å¤Ÿå¤§ï¼Œåœ¨0.001çš„æ˜¾è‘—æ€§æ°´å¹³ä¸Š`chi2.ppf(q=1-0.001,df=2)`(ä¸´ç•Œå€¼ä¸º13.815510557964274)ï¼Œä¹Ÿæ˜¯ç»Ÿè®¡æ˜¾è‘—çš„ï¼ˆå³$p<0.001$ï¼‰ã€‚


```python
print("ğ‘<0.05,df=2,Chi-Squared=%.3f"%chi2.ppf(q=1-0.05,df=2))
print("ğ‘<0.001,df=2,Chi-Squared=%.3f"%chi2.ppf(q=1-0.001,df=2))
```

    ğ‘<0.05,df=2,Chi-Squared=5.991
    ğ‘<0.001,df=2,Chi-Squared=13.816
    

ä½¿ç”¨SciPyçš„`chi2_contingency`æ–¹æ³•è®¡ç®—åˆ—è”è¡¨ï¼Œå…¶è®¡ç®—ç»“æœä¸æ‰‹å·¥è®¡ç®—ç»“æœä¿æŒä¸€è‡´ã€‚


```python
from scipy.stats import chi2_contingency
import numpy as np
schoolboy=(35,50,15)
schoolgirl=(30,25,45)
statistical_data=np.array([schoolboy,schoolgirl])
chi2_results=chi2_contingency(statistical_data)
print("å¡æ–¹å€¼ï¼š%.3f \n På€¼ï¼š%.10f \n è‡ªç”±åº¦:%d \n å¯¹åº”é¢„æœŸé¢‘æ•°ï¼ˆæœŸæœ›å€¼ï¼‰ï¼š\n %s"%chi2_results)
```

    å¡æ–¹å€¼ï¼š23.718 
     På€¼ï¼š0.0000070748 
     è‡ªç”±åº¦:2 
     å¯¹åº”é¢„æœŸé¢‘æ•°ï¼ˆæœŸæœ›å€¼ï¼‰ï¼š
     [[32.5 37.5 30. ]
     [32.5 37.5 30. ]]
    

#### 1.2.3 åæ–¹å·®ä¼°è®¡(Covariance Estimators)
ç»Ÿè®¡å­¦ä¸Šå¸¸ç”¨çš„ç»Ÿè®¡é‡åŒ…æ‹¬å¹³å‡å€¼ã€æ–¹å·®ã€æ ‡å‡†å·®ç­‰ã€‚å¹³å‡å€¼æè¿°äº†æ ·æœ¬é›†åˆçš„ä¸­é—´ç‚¹ï¼›æ–¹å·®æè¿°äº†ä¸€ç»„æ•°æ®ä¸å…¶å¹³å‡å€¼çš„åç¦»ç¨‹åº¦ï¼Œæ–¹å·®è¶Šå°ï¼Œæ•°æ®è¶Šé›†ä¸­ï¼Œæ–¹å·®è¶Šå¤§ï¼Œæ•°æ®è¶Šç¦»æ•£ï¼›æ ‡å‡†å·®æè¿°äº†æ ·æœ¬é›†ä¸­å„ä¸ªæ ·æœ¬ç‚¹åˆ°å‡å€¼çš„è·ç¦»çš„å¹³å‡å€¼ï¼ŒåŒæ–¹å·®ï¼Œæè¿°æ•°æ®é›†çš„é›†èšç¦»æ•£ç¨‹åº¦ã€‚è¿™äº›ç»Ÿè®¡ç»Ÿè®¡é‡æ˜¯é’ˆå¯¹ä¸€ç»´æ•°ç»„ï¼Œåˆ°å¤„ç†é«˜ç»´æ—¶ï¼Œç”¨åˆ°åæ–¹å·®ï¼Œåº¦é‡å¤šä¸ªéšæœºå˜é‡å…³ç³»çš„ç»Ÿè®¡é‡ï¼Œç»“æœå‡ä¸ºæ­£åˆ™æ­£ç›¸å…³ï¼Œéƒ½ä¸ºè´Ÿåˆ™è´Ÿç›¸å…³ï¼Œå‡è¶‹è¿‘äº0ï¼Œåˆ™ä¸ç›¸å…³ã€‚åæ–¹å·®æ˜¯è®¡ç®—ä¸åŒç‰¹å¾ä¹‹é—´çš„ç»Ÿè®¡é‡ï¼Œä¸æ˜¯ä¸åŒæ ·æœ¬ä¹‹é—´çš„ç»Ÿè®¡é‡ã€‚åŒæ—¶ï¼Œåæ–¹å·®çš„å¤§å°ï¼Œé™¤äº†å’Œå˜é‡ä¹‹é—´çš„ç›¸å…³ç¨‹åº¦æœ‰å…³ï¼Œä¹Ÿä¸å˜é‡æœ¬èº«çš„æ–¹å·®å¤§å°æœ‰å…³ï¼Œå› æ­¤å¼•å…¥ç›¸å…³ç³»æ•°ï¼Œç§»é™¤å˜é‡æœ¬èº«çš„å½±å“ã€‚åœ¨åæ–¹å·®è®¡ç®—æ—¶å¯ä»¥ä½¿ç”¨åæ–¹å·®ï¼ˆçŸ©é˜µï¼‰è®¡ç®—å…¬å¼ï¼ˆæŸ¥çœ‹æ–¹å·®å’Œåæ–¹å·®éƒ¨åˆ†ï¼‰ï¼Œè€Œæœ‰æ—¶å¹¶ä¸ä½¿ç”¨å…¨éƒ¨çš„æ ·æœ¬æ•°æ®è®¡ç®—åæ–¹å·®çŸ©é˜µï¼Œè€Œæ˜¯åˆ©ç”¨éƒ¨åˆ†æ ·æœ¬æ•°æ®è®¡ç®—ï¼Œè¿™æ˜¯å°±éœ€è¦è€ƒè™‘æ ·æœ¬è®¡ç®—å¾—åˆ°çš„åæ–¹å·®çŸ©é˜µæ˜¯å¦å’Œæ€»ä½“çš„åæ–¹å·®çŸ©é˜µç›¸åŒå’Œè¿‘ä¼¼ã€‚å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œä¼°è®¡æ€»ä½“çš„åæ–¹å·®çŸ©é˜µå¿…é¡»åœ¨æ ·æœ¬çš„æ€§è´¨ï¼ˆå¤§å°sizeï¼Œç»“æ„structureï¼ŒåŒè´¨æ€§homogeneityï¼‰å¯¹ä¼°è®¡è´¨é‡æœ‰å¾ˆå¤§å½±å“ä¸‹è¿›è¡Œï¼Œåœ¨`sklearn.covariance`æ¨¡å—ä¸­åˆ™æä¾›äº†å¤šä¸ªå¥å£®çš„åæ–¹å·®ä¼°è®¡ç®—æ³•ï¼Œå¼•åˆ—è¡¨å¦‚ä¸‹ï¼š

| åæ–¹å·®ä¼°è®¡æ–¹æ³•                                        | è§£é‡Š                                                                     |
|------------------------------------------------|------------------------------------------------------------------------|
| covariance.EmpiricalCovariance(*[,Â â€¦])         | æœ€å¤§ä¼¼ç„¶åæ–¹å·®ä¼°è®¡ Maximum likelihood covariance estimator                                |
| covariance.EllipticEnvelope(*[,Â â€¦])            | ç”¨äºæ£€æµ‹é«˜æ–¯åˆ†å¸ƒæ•°æ®é›†ä¸­å¼‚å¸¸å€¼çš„å¯¹è±¡ An object for detecting outliers in a Gaussian distributed dataset.    |
| covariance.GraphicalLasso([alpha,Â mode,Â â€¦])    | å¸¦L1æƒ©ç½šä¼°è®¡é‡çš„ç¨€ç–é€†åæ–¹å·®ä¼°è®¡ Sparse inverse covariance estimation with an l1-penalized estimator.   |
| covariance.GraphicalLassoCV(*[,Â alphas,Â â€¦])    | ç¨€ç–é€†åæ–¹å·®w/äº¤å‰éªŒè¯l1æƒ©ç½šçš„é€‰æ‹© Sparse inverse covariance w/ cross-validated choice of the l1 penalty. |
| covariance.LedoitWolf(*[,Â store_precision,Â â€¦]) |LedoitWolfä¼°è®¡é‡  LedoitWolf Estimator                                                   |
| covariance.MinCovDet(*[,Â store_precision,Â â€¦])  |æœ€å°åæ–¹å·®è¡Œåˆ—å¼(MCD):åæ–¹å·®çš„ç¨³å¥ä¼°è®¡  Minimum Covariance Determinant (MCD): robust estimator of covariance.  |
| covariance.OAS(*[,Â store_precision,Â â€¦])        |Oracleé€¼è¿‘æ”¶ç¼©ä¼°è®¡  Oracle Approximating Shrinkage Estimator                               |
| covariance.ShrunkCovariance(*[,Â â€¦])            |åæ–¹å·®ç¼©æ°´ï¼ˆshrinkageï¼‰ä¼°è®¡ Covariance estimator with shrinkage                                    |
| covariance.empirical_covariance(X,Â *[,Â â€¦])     |è®¡ç®—æœ€å¤§ä¼¼ç„¶åæ–¹å·®ä¼°è®¡é‡ Computes the Maximum likelihood covariance estimator                   |
| covariance.graphical_lasso(emp_cov,Â alpha,Â *)  | l1-æƒ©ç½šé¡¹åæ–¹å·®ä¼°è®¡é‡ l1-penalized covariance estimator                                      |
| covariance.ledoit_wolf(X,Â *[,Â â€¦])              | ä¼°è®¡ç¼©æ°´çš„Ledoit-Wolfåæ–¹å·®çŸ©é˜µ Estimates the shrunk Ledoit-Wolf covariance matrix.                    |
| covariance.oas(X,Â *[,Â assume_centered])        |ç”¨Oracleè¿‘ä¼¼ç¼©æ°´ç®—æ³•ä¼°è®¡åæ–¹å·® Estimate covariance with the Oracle Approximating Shrinkage algorithm. |
| covariance.shrunk_covariance(emp_cov[,Â â€¦])     |è®¡ç®—åœ¨å¯¹è§’çº¿ä¸Šç¼©æ°´çš„åæ–¹å·®çŸ©é˜µ Calculates a covariance matrix shrunk on the diagonal                  |

ä¸‹è¿°å‡è®¾äº†ä¸€ä¸ªåæ–¹å·®çŸ©é˜µï¼Œå¹¶æ ¹æ®è¯¥åæ–¹å·®çŸ©é˜µç”Ÿäº§ä¸€ç»„æ•°æ®é›†ï¼Œåˆ†å¸ƒä½¿ç”¨äº†`sklearn.covariance `æä¾›çš„GraphicalLassoCVï¼ŒEmpiricalCovarianceï¼ŒMinCovDetï¼Œä»¥åŠnumpyåº“æä¾›çš„np.cov()æ–¹æ³•è¿›è¡Œè®¡ç®—æ¯”è¾ƒè§‚å¯Ÿï¼Œå…¶ç»“æœç›¸è¿‘ï¼Œå‘çœŸå®å‡è®¾çš„åæ–¹å·®çŸ©é˜µå€¼é è¿‘ã€‚


```python
import numpy as np
from sklearn.covariance import GraphicalLassoCV,EmpiricalCovariance,MinCovDet
#å‡è®¾çš„åæ–¹å·®çŸ©é˜µï¼ŒåŒ…å«4ä¸ªç‰¹å¾é‡
true_cov=np.array([[0.8, 0.0, 0.2, 0.0],
                  [0.0, 0.4, 0.0, 0.0],
                  [0.2, 0.0, 0.3, 0.1],
                  [0.0, 0.0, 0.1, 0.7]])
np.random.seed(0)
#ç”Ÿæˆæ»¡è¶³å‡è®¾åæ–¹å·®çŸ©é˜µçš„ç‰¹å¾å€¼
X = np.random.multivariate_normal(mean=[0, 0, 0, 0], cov=true_cov,size=200)
#A-ä½¿ç”¨GraphicalLassoCVæ–¹æ³•
print("A-GraphicalLassoCV algorithm:\n{},estimated location(the estimated mean):{}".format(np.around(GraphicalLassoCV().fit(X).covariance_, decimals=3),np.around(cov.location_, decimals=3)))

#B-EmpiricalCovariance
print("A-EmpiricalCovariance algorithm:\n{}".format(np.around(EmpiricalCovariance().fit(X).covariance_, decimals=3)))

#C-MinCovDet
print("A-MinCovDet:\n{}".format(np.around(MinCovDet().fit(X).covariance_, decimals=3)))

#D-np.cov
print("A-np.cov:\n{}".format(np.around(np.cov(X.T), decimals=3)))
```

    A-GraphicalLassoCV algorithm:
    [[0.816 0.051 0.22  0.017]
     [0.051 0.364 0.018 0.036]
     [0.22  0.018 0.322 0.094]
     [0.017 0.036 0.094 0.69 ]],estimated location(the estimated mean):[0.073 0.04  0.038 0.143]
    A-EmpiricalCovariance algorithm:
    [[0.816 0.059 0.228 0.009]
     [0.059 0.364 0.025 0.044]
     [0.228 0.025 0.322 0.103]
     [0.009 0.044 0.103 0.69 ]]
    A-MinCovDet:
    [[ 0.741 -0.005  0.162  0.089]
     [-0.005  0.305  0.024  0.061]
     [ 0.162  0.024  0.237  0.117]
     [ 0.089  0.061  0.117  0.55 ]]
    A-np.cov:
    [[0.82  0.059 0.229 0.009]
     [0.059 0.366 0.025 0.044]
     [0.229 0.025 0.324 0.103]
     [0.009 0.044 0.103 0.694]]
    

### 1.3 åŸºäºç™¾åº¦POIè¿ç»­è·ç¦»èšç±»å±‚çº§ä¸‹åŸå¸‚ç”Ÿæ´»åœˆçš„ç©ºé—´åˆ†å¸ƒç»“æ„
#### 1.3.1 è¿ç»­è·ç¦»èšç±»ä¸ä¸šæ€åˆ†å¸ƒç»“æ„è®¡ç®—
POIç©ºé—´åˆ†å¸ƒç»“æ„çš„åˆ†æåŒ…æ‹¬ä¸‰éƒ¨åˆ†çš„å†…å®¹ï¼Œä¸€ä¸ªæ˜¯ï¼ŒåŸºäºPOIä½ç½®ä¿¡æ¯ç ”ç©¶åŸå¸‚ç”Ÿæ´»åœˆçš„ç©ºé—´å±‚çº§å˜åŒ–ç‰¹å¾ï¼›å¦ä¸€ä¸ªæ˜¯ï¼ŒåŸºäºPOIä¸€çº§è¡Œä¸šåˆ†ç±»ï¼Œç ”ç©¶åŸå¸‚ç”Ÿæ´»åœˆçš„ä¸šæ€ç»“æ„ï¼›å†è€…ï¼Œé€šè¿‡ä¿¡æ¯ç†µå’Œå‡è¡¡åº¦åˆ†æç”Ÿæ´»åœˆè¡Œä¸šç±»å‡ºç°çš„å‡è´¨æ€§ã€‚

1. å¯¹äºåŸå¸‚ç”Ÿæ´»åœˆçš„ç©ºé—´å±‚çº§å˜åŒ–ç‰¹å¾çš„ç ”ç©¶æ˜¯ç»™å®šè¿ç»­èšç±»çš„è·ç¦»eps=list(range(20,520,10)) =[ 20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130, 140,150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270,280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400,410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510]ï¼Œåº”ç”¨DBSCANèšç±»æ–¹æ³•åˆ†ææ¯ä¸€å±‚çº§ä¸‹POIé›†èšåˆ†å¸ƒçš„æƒ…å†µï¼Œèšç±»50ä¸ªè·ç¦»å±‚çº§ä¹‹åï¼Œé€šè¿‡åˆ†åˆ«ç»˜åˆ¶POIç‹¬ç«‹ç‚¹ã€èšç±»æ€»æ•°ä¸èšç±»è·ç¦»ä¹‹é—´çš„æŠ˜çº¿å›¾ï¼Œåˆ©ç”¨pythonåº“kneedè®¡ç®—æ›²çº¿æ‹ç‚¹å¯¹åº”çš„è·ç¦»å€¼ï¼Œè§‚å¯Ÿå±‚çº§æ•°æ®å˜åŒ–å¹¶æ•æ‰è¿ç»­å±‚çº§å˜åŒ–è¿‡ç¨‹ä¸­çš„å…³é”®å±‚çº§ï¼Œåˆ†æè¯¥è·ç¦»å±‚çº§ä¸‹ç”Ÿæ´»åœˆç©ºé—´åˆ†å¸ƒçš„ç‰¹ç‚¹ã€‚åŒæ—¶ï¼Œç»˜åˆ¶èšç±»é¢‘æ•°ä¸èšç±»è·ç¦»å…³ç³»çš„ç®±å‹å›¾ï¼Œå¯»æ‰¾è¿ç»­å±‚çº§å˜åŒ–ä¸‹çš„æœ€å¤§é¢‘æ•°å‡ºç°çš„ä½ç½®æ‰€å¯¹åº”çš„è·ç¦»ï¼Œæ‰¾åˆ°åŸºäºPOIåŸå¸‚æœ€å¤§ç”Ÿæ´»åœˆçš„å…·ä½“èŒƒå›´ã€‚

2. å¯¹äºä¸šæ€ç»“æ„ï¼Œåˆ™å‚è€ƒå®˜æ–¹Sklearnæ¡ˆä¾‹[Visualizing the stock market structure](https://scikit-learn.org/stable/auto_examples/applications/plot_stock_market.html#sphx-glr-auto-examples-applications-plot-stock-market-py)ã€‚å› ä¸ºPOIä½ç½®çš„èšç±»ï¼Œå¯ä»¥æ‰¾åˆ°è¡Œä¸šåˆ†å¸ƒçš„ç©ºé—´ç‰¹å¾ï¼Œä½†æ˜¯ç¼ºå¤±ç±»åˆ«æ ‡ç­¾ï¼Œæ— æ³•æ¢ç©¶è¡Œä¸šç±»åˆ«ä¹‹é—´çš„å…³ç³»ï¼Œå› æ­¤åŸºäºPOIçš„ä¸€çº§è¡Œä¸šåˆ†ç±»ï¼Œé€šè¿‡è®¡ç®—æ‰€æœ‰å±‚çº§ä¸‹å„ä¸ªç”Ÿæ´»åœˆè¡Œä¸šç±»å‡ºç°çš„ç›¸å…³æ€§ï¼Œæ¢ç´¢åŠŸèƒ½éœ€æ±‚ä¹‹é—´çš„å…³è”åœ¨è¿ç»­å±‚çº§ä¸‹çš„å˜åŒ–ã€‚è®¡ç®—è¡Œä¸šç±»æ‰€å±èšç±»ç°‡çš„é¢‘æ•°ï¼Œ é‡‡ç”¨covariance.GraphicalLassoCV( )åæ–¹å·®é€†çŸ©é˜µå’Œaffinity_propagation()APèšç±»ç®—æ³•è®¡ç®—ä¸åŒå±‚çº§ä¸‹ç”Ÿæ´»åœˆæ‰€åŒ…å«åŸå¸‚åŠŸèƒ½ä¹‹é—´çš„å…³è”ç¨‹åº¦ã€‚

3. å¯¹äºä¿¡æ¯ç†µå’Œå‡è¡¡åº¦åˆ†æï¼Œå…¶ä¿¡æ¯ç†µå…¬å¼ä¸ºï¼š$H=- \sum_{i=1}^N  P_{i}log  P_{i}$ï¼Œå…¶ä¸­$P_{i}$ä¸ºç°‡ä¸­è¡Œä¸šç±»é¢‘æ•°å ç°‡ä¸­POIæ€»æ•°çš„ç™¾åˆ†æ¯”ï¼›$i$ä¸ºèšç±»ç°‡çš„æ•°é‡ã€‚ä¿¡æ¯ç†µçš„é«˜ä½åæ˜ äº†åŸå¸‚è¡Œä¸šç±»çš„å‡è¡¡ç¨‹åº¦ï¼Œç†µå€¼è¶Šé«˜ï¼Œè¡¨æ˜ä¸åŒè¡Œä¸šç±»å‹è¶Šå¤šï¼Œå„ç±»å‹çš„é¢‘æ•°ç›¸å·®è¶Šå°ï¼Œè¡Œä¸šç±»åˆ†å¸ƒè¶Šå‡è¡¡ã€‚å½“å„ç±»å‹çš„é¢‘æ•°ç›¸ç­‰å³$P_1=P_2=â‹¯=P_N=1/N$æ—¶ï¼Œç†µå€¼è¾¾åˆ°æœ€å¤§ï¼Œè¡¨æ˜è¡Œä¸šç±»è¾¾åˆ°äº†æœ€å¤§å‡è¡¡çŠ¶æ€ã€‚å› ä¸ºè®¡ç®—æœ‰50ä¸ªå±‚çº§ï¼Œè€Œæ¯ä¸€å±‚çº§èšç±»çš„å„ç°‡å¤§å°ä¸åŒï¼Œæ‰€è®¡ç®—çš„ä¿¡æ¯ç†µç¼ºä¹å¯æ¯”æ€§ï¼Œå› æ­¤è®¡ç®—å®é™…ç†µå€¼ä¸æœ€å¤§ç†µå€¼ä¹‹æ¯”çš„å‡è¡¡åº¦$J$ï¼Œå…¬å¼ä¸ºï¼š$J= \frac{H}{ H_{m} } = -  \frac{ \sum_i^N log p_{i}  }{logN} $ã€‚å‡è¡¡åº¦è¶Šå¤§ï¼Œè¡Œä¸šç±»å‡ºç°çš„å‡è´¨æ€§è¶Šå¼ºï¼›ç›¸åï¼Œå‡è´¨æ€§è¶Šå¼±ï¼ŒæŸä¸€ç±»åˆ™å æœ‰ç›¸å¯¹æ•°é‡ä¼˜åŠ¿ã€‚


```mermaid
classDiagram

poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ --> å»ºç«‹æ•°æ®é›†Bunch : a.POIè¯»å–å¹¶å»ºç«‹æ•°æ®é›†

poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ : a. è¯»å–POI.jsonæ ¼å¼æ•°æ®ï¼Œå¹¶å»ºç«‹SklearnBunchæ•°æ®é›†
poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ : b. ç±»çš„å®ä¾‹åŒ–ä¸æ•°æ®åˆå§‹åŒ–
poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ : c. æ‰§è¡Œè¿ç»­è·ç¦»DBCSCANèšç±»
poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ : d. ä¿æŒDBCSCANèšç±»ç»“æœä¸ºshpæ ¼å¼åœ°ç†ä¿¡æ¯æ•°æ®å¹¶æ‰“å°æ˜¾ç¤º
poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ : e. è¡Œä¸šç±»æ ‡ä¸èšç±»ç°‡çš„å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ
poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ : f. POIç©ºé—´ç»“æ„

å»ºç«‹æ•°æ®é›†Bunch : 1.è¯»å–.jsonæ ¼å¼çš„POIæ•°æ®
å»ºç«‹æ•°æ®é›†Bunch : 2.å»ºç«‹Sklearnä¸‹çš„Bunchæ•°æ®é›†
å»ºç«‹æ•°æ®é›†Bunch : poi_json2sklearn_bunch(fps)

å»ºç«‹æ•°æ®é›†Bunch --> ç±» poi_spatial_distribution_structure: b.ç±»å®ä¾‹åŒ–ä¸æ•°æ®åˆå§‹åŒ–
ç±» poi_spatial_distribution_structure : __init__(self,poi_dataBunch,eps,min_samples,save_path)
ç±» poi_spatial_distribution_structure : frequency_array(slef,array)
ç±» poi_spatial_distribution_structure : clustering_DBSCAN(self,eps_single)
ç±» poi_spatial_distribution_structure : clustering_batch_computing(self)
ç±» poi_spatial_distribution_structure : poi2shp(self)
ç±» poi_spatial_distribution_structure : poi_chi_2Test(self)
ç±» poi_spatial_distribution_structure : POI_structure(self)

poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ --> è¿ç»­è·ç¦»DBCSCANèšç±» : c.BCSCANèšç±»
è¿ç»­è·ç¦»DBCSCANèšç±» : æ ¹æ®èšç±»è·ç¦»æ‰¹é‡DBSCANèšç±»
è¿ç»­è·ç¦»DBCSCANèšç±» : å•æ¬¡DBSCANèšç±»
è¿ç»­è·ç¦»DBCSCANèšç±» : clustering_batch_computing(self)
è¿ç»­è·ç¦»DBCSCANèšç±» : clustering_DBSCAN(self,eps_single)
è¿ç»­è·ç¦»DBCSCANèšç±» --|> ç±» poi_spatial_distribution_structure :c

poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ --> DBCSCANèšç±»ç»“æœä¿å­˜ä¸ºshp : d.DBCSCANèšç±»ä¿å­˜
DBCSCANèšç±»ç»“æœä¿å­˜ä¸ºshp : è·ç¦»èšç±»ä¿å­˜
DBCSCANèšç±»ç»“æœä¿å­˜ä¸ºshp : æ‰“å°å›¾åƒ
DBCSCANèšç±»ç»“æœä¿å­˜ä¸ºshp : poi2shp(self)
DBCSCANèšç±»ç»“æœä¿å­˜ä¸ºshp --|> ç±» poi_spatial_distribution_structure :d

poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ --> å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ :e.å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ
å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ : å»ºç«‹åˆ—è”è¡¨
å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ : å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ
å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ : poi_chi_2Test(self)
å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ  --|> ç±» poi_spatial_distribution_structure :e

poi_ç©ºé—´ç»“æ„åŒ…å«åŠŸèƒ½ --> POIç©ºé—´ç»“æ„ : f.POIç©ºé—´ç»“æ„
POIç©ºé—´ç»“æ„ : GraphicalLassoCVåæ–¹å·®è®¡ç®—
POIç©ºé—´ç»“æ„ : affinity_propagationèšç±»åæ–¹å·®
POIç©ºé—´ç»“æ„ : å›¾è¡¨æ‰“å°ä¸å•ç‹¬ä¿å­˜
POIç©ºé—´ç»“æ„ : POI_structure(self)
POIç©ºé—´ç»“æ„  --|> ç±» poi_spatial_distribution_structure :f
```

åœ¨POIéƒ¨åˆ†é˜è¿°äº†æ•°æ®çˆ¬å–çš„æ–¹æ³•ï¼Œå¹¶å°†æ•°æ®åˆ†åˆ«å­˜å‚¨ä¸º.csvå’Œ.jsonä¸¤ç§æ•°æ®æ ¼å¼ã€‚æ­¤å¤„è¯»å–å·²ç»ä¿å­˜çš„.jsonæ•°æ®æ ¼å¼çš„POIï¼Œæå–ç»çº¬åº¦ä¿¡æ¯('location')å’Œåˆ†ç±»ä¿¡æ¯('tag')ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸ºsklearnçš„Bunchæ•°æ®æ ¼å¼ã€‚


```python
import util
import os

def poi_json2sklearn_bunch(fps,save_path):
    import json
    from sklearn.preprocessing import LabelEncoder
    from sklearn.datasets import base
    import numpy as np
    import pickle 
    '''
    function - æå–åˆ†ææ‰€éœ€æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºsklerançš„bunchå­˜å‚¨æ–¹å¼ï¼Œç»Ÿä¸€æ ¼å¼ï¼Œæ–¹ä¾¿è¯»å–ã€‚(æ³¨æ„poiè¡Œä¸šåˆ†ç±»ç±»æ ‡çš„è®¾ç½®)
    
    Paras:
    fps - .jsonæ–‡ä»¶åˆ—è¡¨
    '''
    poi_info=[]
    KeyError_count=0
    for fn in fps:
        with open(fn,'r') as f:
            json_decodes=json.load(f)
        for info in json_decodes:          
            try:
                poi_info.append((info['location']['lat'],info['location']['lng'],info['detail_info']['tag']))
            except KeyError: #æœ‰äº›æ•°æ®ä¸­ä¸åŒ…å«'tag'ä¿¡æ¯ï¼Œå³æ²¡æœ‰è¯¥å­—å…¸çš„é”®
                KeyError_count+=1   
  
    print("Oops! KeyError_count:%d"%KeyError_count)
    poi_coordi=np.array([(v[0],v[1]) for v in poi_info])  #ç»çº¬åº¦ä¿¡æ¯
    poi_classification=[v[2].split(';') for v in poi_info]
    poi_classifi_firstLevle=np.array([v[0] for v in poi_classification])  #ä¸€çº§åˆ†ç±»ä¿¡æ¯
    poi_classifi_secondLevle=np.array([v[1] if len(v)>1 else 'None' for v in poi_classification ])  #äºŒçº§åˆ†ç±»ä¿¡æ¯ï¼Œå¤„ç†å¯èƒ½ä¸å­˜åœ¨äºŒçº§åˆ†ç±»åçš„æƒ…å†µ
     
    class_label=LabelEncoder()  #ä»¥æ•´æ•°å½¢å¼ç¼–ç åˆ†ç±»å
    poiLabel_1=class_label.fit_transform(poi_classifi_firstLevle)    
    poiLabel_1_mapping=[(idx,label) for idx,label in enumerate(class_label.classes_)]  #å»ºç«‹ä¸€çº§åˆ†ç±»åå’Œæ•´æ•°ç¼–ç çš„æ˜ å°„åˆ—è¡¨
    
    poiLabel_2=class_label.fit_transform(poi_classifi_secondLevle)
    poiLabel_2_mapping=[(idx,label) for idx,label in enumerate(class_label.classes_)]  #å»ºç«‹äºŒçº§åˆ†ç±»åå’Œæ•´æ•°ç¼–ç çš„æ˜ å°„åˆ—è¡¨

    data=poi_coordi
    target=np.stack((poiLabel_1,poiLabel_2),axis=-1)
    target_names={'1_level_label':poiLabel_1_mapping,'2_level_label':poiLabel_2_mapping}
    dataBunch=base.Bunch(DESCR=r'spatial points datasets of poi',data=data,feature_names=["XCoordinate","yCoordinate"],target=target,target_names=target_names)  #å»ºç«‹sklearnçš„æ•°æ®å­˜å‚¨æ ¼å¼bunch
    
    with open(os.path.join(save_path,'POI_dataset_bunch.pkl'),'wb') as f:
        pickle.dump(dataBunch,f)     
    return dataBunch

dirpath='./data/xianPOI_36/'
fileType=["json"]
poi_paths=util.filePath_extraction(dirpath,fileType)

'''å±•å¹³åˆ—è¡¨å‡½æ•°'''
flatten_lst=lambda lst: [m for n_lst in lst for m in flatten_lst(n_lst)] if type(lst) is list else [lst]
poi_fp=flatten_lst([[os.path.join(key,val) for val in poi_paths[key]] for key in poi_paths.keys()])

save_path=r'./data/poi_clustering'
poi_dataBunch=poi_json2sklearn_bunch(poi_fp,save_path)    
```

    Oops! KeyError_count:17
    

å°†è¿ç»­è·ç¦»èšç±»è®¡ç®—ä¸ä¸šæ€ç»“æ„çš„åˆ†æå°è£…åœ¨`poi_spatial_distribution_structure`ç±»ä¸‹ï¼Œå…·ä½“ç±»ä¸‹å‡½æ•°ä¹‹é—´çš„å…³ç³»å¯ä»¥å‚è€ƒä»£ç çš„ç»“æ„å›¾ã€‚å…¶ä¸­éœ€è¦æ³¨æ„å‡½æ•°ä¹‹é—´å˜é‡è°ƒç”¨çš„å…³ç³»ï¼Œå°½å¯èƒ½è®©ä»£ç ç»“æ„æ¸…æ™°æ˜“è¯»ï¼›åŒæ—¶ä¸ºé¿å…é‡å¤è®¡ç®—ï¼Œå¿…è¦çš„ç»“æœæ•°æ®éœ€è¦ä¿å­˜åœ¨ç¡¬ç›˜ç©ºé—´ä¸‹ï¼Œæ–¹ä¾¿ä¹‹åçš„åˆ†æåŠ ä»¥è¯»å–è°ƒç”¨ã€‚å¯¹äºä¸šæ€ç»“æ„çš„è®¡ç®—æ˜¯å°†èšç±»çš„ç»“æœå³æ¯ä¸ªPOIç‚¹å¯¹åº”çš„ç°‡ç±»æ ‡ï¼Œä»¥åŠä¸€çº§è¡Œä¸šåˆ†ç±»å¯¹åº”èµ·æ¥å»ºç«‹åˆ—è”è¡¨ï¼Œå…¶æ¨ªå‘ä¸ºè¡Œä¸šç±»æ‰€å±èšç±»ç°‡é¢‘æ•°ï¼Œçºµå‘ä¸ºè¡Œä¸šåˆ†ç±»ã€‚å¯¹åˆ—è”è¡¨è®¡ç®—åæ–¹å·®èƒ½å¤Ÿå¾—çŸ¥è¡Œä¸šï¼ˆä¸€çº§ï¼‰åˆ†ç±»ä¸èšç±»ç°‡çš„å…³è”ç¨‹åº¦ï¼Œä¾‹å¦‚å¯¹äºä¸€ä¸ªè·ç¦»å±‚çº§ï¼Œå½¢æˆæœ‰å¤šä¸ªç°‡ï¼Œæ¯ä¸ªç°‡ä¸­é€šå¸¸ä¼šåŒ…å«å¤šä¸ªè¡Œä¸šåˆ†ç±»çš„ç‚¹ï¼Œä¸åŒåˆ†ç±»ç‚¹å æ®çš„æ¯”ä¾‹ä¸åŒï¼ˆå³é¢‘æ•°ä¸åŒï¼‰ï¼Œé‚£ä¹ˆå“ªäº›åˆ†ç±»çš„ç»„åˆå®¹æ˜“å½¢æˆä¸€ä¸ªç°‡ï¼Ÿæˆ–è€…å½¢æˆçš„ç°‡æ›´å®¹æ˜“å‡ºç°å“ªäº›è¡Œä¸šåˆ†ç±»çš„ç»„åˆï¼Ÿè·å¾—äº†ååº”åˆ†ç±»é—´ç›¸å…³æ€§çš„åæ–¹å·®çŸ©é˜µï¼Œå¯ä»¥å¯¹å…¶æ‰§è¡Œèšç±»ï¼Œç›¸å…³æ€§å¼ºçš„è¡Œä¸šåˆ†ç±»ä¼šèšé›†åœ¨ä¸€èµ·ï¼Œå½¢æˆå¤šä¸ªè¡Œä¸šç»„åˆçš„ç°‡ï¼Œä»è€Œèƒ½å¤Ÿç¡®å®šå“ªä¸ªè¡Œä¸šåˆ†ç±»ä¸å“ªä¸ªæ›´å®¹æ˜“å‡ºç°åœ¨ä¸€ä¸ªåŒºåŸŸä¸­ï¼ˆç°‡ï¼‰ã€‚

å¯¹åæ–¹å·®çŸ©é˜µæ‰§è¡Œäº†å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒï¼Œä»ä¸‹è¿°ç»“æœä¸­åˆ†æå¾—åˆ°èšç±»è·ç¦»90måŠå°äº90mçš„æ‰€æœ‰èšç±»çš„ç»“æœå› ä¸ºå…¶$p$å€¼å¤§äº0.05ï¼Œå³åœ¨è¿™äº›å±‚çº§ä¹‹ä¸‹ï¼Œæ— æ³•ç¡®å®šè¡Œä¸šä¸€çº§åˆ†ç±»å¯¹èšç±»ç°‡çš„å½±å“ã€‚å¤§äº90mçš„èšç±»ï¼Œå› ä¸º$p<0.05$ï¼Œå› æ­¤å¯ä»¥ç¡®å®šè¡Œä¸šåˆ†ç±»çš„ä¸åŒç»„åˆå¯¹ç°‡çš„å½¢æˆæœ‰å…³è”ã€‚å› æ­¤å¤§äº90mçš„èšç±»ï¼Œå…¶è¡Œä¸šä¸šæ€çš„ç»“æ„åˆ†æç»“æœæ˜¯æœ‰æ„ä¹‰çš„ã€‚


```python
class poi_spatial_distribution_structure:
    '''
    function - ä½¿ç”¨DBSCANç®—æ³•å®ç°è¿ç»­è·ç¦»èšç±»å’Œç©ºé—´ç»“æ„åˆ†æ

    Paras:
    poi_dataBunch - å¾…èšç±»çš„æ•°æ®ï¼ŒåŒ…æ‹¬åœ°ç†ç©ºé—´ç‚¹åæ ‡ï¼Œç±»æ ‡ï¼Œä»¥åŠç±»æ ‡æ˜ å°„
    eps - èšç±»è·ç¦»
    min_samples - é‚»åŸŸæ ·æœ¬æ•°é‡
    '''
    def __init__(self,poi_dataBunch,eps,min_samples,save_path):        
        self.data_degree=poi_dataBunch.data
        self.data_dist=poi_dataBunch.data*(2 * math.pi * 6378137.0)/ 360 #å¦‚æœè¯»å–çš„æ˜¯åº¦ï¼Œå°†å…¶è½¬æ¢ä¸ºè·ç¦»å•ä½
        self.eps=eps
        self.min_samples=min_samples
        self.save_path=save_path           
        self.poi_label=poi_dataBunch.target[:,0]   
        self.label_1_mapping=poi_dataBunch.target_names["1_level_label"]       
        
    def frequency_array(slef,array):
        '''
        function - æ‰“å°æ•°ç»„é¢‘æ•°
        
        Paras:
        array - å¾…ç»Ÿè®¡æ•°ç»„
        '''
        unique, counts=np.unique(array, return_counts=True)
        print(np.asarray((unique, counts)).T)        
    
    def clustering_DBSCAN(self,eps_single):
        import time
        from sklearn import cluster
        import numpy as np
        '''
        function - å•æ¬¡èšç±»
        
        Paras:
        eps_single - å•æ¬¡èšç±»è·ç¦»
        '''
        db=cluster.DBSCAN(eps=eps_single,min_samples=self.min_samples,metric='euclidean') #meter=degree*(2 * math.pi * 6378137.0)/ 360  degree=50/(2 * math.pi * 6378137.0) * 360ï¼Œåœ¨è°ƒå‚æ—¶ï¼Œepsä¸ºé‚»åŸŸçš„è·ç¦»é˜ˆå€¼ï¼Œè€Œåˆ†æçš„æ•°æ®ä¸ºç»çº¬åº¦æ•°æ®ï¼Œä¸ºäº†ä¾¿äºè°ƒå‚ï¼Œå¯ä¾æ®ä¸Šè¿°å…¬å¼å¯ä»¥åœ¨ç±³å’Œåº¦ä¹‹é—´äº’ç›¸è½¬æ¢ï¼Œæ­¤æ—¶è®¾ç½®eps=0.0008ï¼Œçº¦ä¸º90mï¼Œå¦‚æœpoiçš„ç©ºé—´ç‚¹ä¹‹é—´è·ç¦»åœ¨90må†…åˆ™ä¸ºä¸€ç°‡ï¼›min_samplesä¸ºæ ·æœ¬ç‚¹è¦æˆä¸ºæ ¸å¿ƒå¯¹è±¡æ‰€éœ€è¦çš„é‚»åŸŸæ ·æœ¬æ•°é˜ˆå€¼ã€‚å‚æ•°éœ€è¦è‡ªè¡Œæ ¹æ®æ‰€åˆ†æçš„æ•°æ®ä¸æ–­è°ƒè¯•ï¼Œç›´è‡³è¾¾åˆ°è¾ƒå¥½èšç±»çš„ç»“æœã€‚
        y_pred=db.fit_predict(self.data_dist)  #è·å–èšç±»é¢„æµ‹ç±»æ ‡

        return y_pred,np.unique(y_pred)          

    def clustering_batch_computing(self):
        from tqdm import tqdm 
        import numpy as np
        import pandas as pd
        '''
        function - æ ¹æ®èšç±»è·ç¦»åˆ—è¡¨æ‰¹é‡å¤„ç†ï¼ˆèšç±»ï¼‰
        '''          
        global poi_clusteringPred_dict #å­˜å‚¨èšç±»é¢„æµ‹ç»“æœï¼Œé…ç½®ä¸ºç±»çš„å…¨å±€å˜é‡ï¼Œé¿å…é‡å¤è®¡ç®—   
        poi_clusteringPred_dict={}
        for eps_single in tqdm(self.eps):
            y_pred,pred_label=self.clustering_DBSCAN(eps_single)
            field_name=r'%s_POI'%eps_single #å­—ç¬¦ä¸²æ ¼å¼åŒ–è¾“å‡ºæ–‡ä»¶å
            poi_clusteringPred_dict[field_name]=y_pred   
        print("å®Œæˆè¿ç»­è·ç¦»èšç±»è®¡ç®—ï¼")
        
    def poi2shp(self):
        import os
        import geopandas as gpd
        from shapely.geometry import Point   
        import pandas as pd
        '''
        function - ä¿å­˜èšç±»ç»“æœäº.shpæ–‡ä»¶ä¸­,åŠæ‰“å°ä¸€ç»„é¢„è§ˆ
        
        Paras:
        poi_df - åŒ…å«åœ°ç†åæ ‡ï¼Œå’Œèšç±»é¢„æµ‹å€¼çš„DataFrameæ ¼å¼æ•°æ®
        save_path - ä¿å­˜çš„æ ¹ç›®å½•
        '''
        print("A-è¿ç»­è·ç¦»èšç±»ç»“æœä¿å­˜ä¸º.shpæ ¼å¼æ•°æ®ï¼ŒåŠæ‰“å°ä¸€ç»„é¢„è§ˆ")
        save_fp=os.path.join(self.save_path,'poi_clustering_pred.shp')
        
        poi_clusteringPred_df=pd.DataFrame.from_dict(poi_clusteringPred_dict)
        poi_coordi_df=pd.DataFrame(self.data_degree,columns=('lat','lon'))     
        poi_concat_df=pd.concat([poi_coordi_df,poi_clusteringPred_df],axis=1)        
        
        poi_geoDF=poi_concat_df.copy(deep=True)
        poi_geoDF['geometry']=poi_geoDF.apply(lambda row:Point(row.lon,row.lat),axis=1) 
        crs={'init': 'epsg:4326'} #é…ç½®åæ ‡ç³»ç»Ÿï¼Œå‚è€ƒï¼šhttps://spatialreference.org/  
        poi_gpd=gpd.GeoDataFrame(poi_geoDF,crs=crs)
        poi_gpd_clean=poi_gpd.dropna(subset=['lon','lat'])
        poi_gpd_clean.to_file(save_fp)
        poi_gpd_clean.plot(column=poi_gpd_clean.columns[15],markersize=1,figsize=(15,15))           
        
    def poi_chi_2Test(self):
        from scipy.stats import chi2_contingency
        import numpy as np        
        import pickle,os
        '''
        function - å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒï¼Œåˆ†æPOIä¸€çº§è¡Œä¸šåˆ†ç±»ç±»æ ‡ä¸èšç±»ç°‡çš„ç›¸å…³æ€§
        '''        
        global CT_dict
        CT_dict={}
        chi_2Test_dict={}
        for key in poi_clusteringPred_dict.keys():
            pred_label=np.hstack((poi_clusteringPred_dict[key].reshape(-1,1),self.poi_label.reshape(-1,1))) #æ°´å¹³ç»„åˆèšç±»é¢„æµ‹å€¼å’Œè¡Œä¸šåˆ†ç±»ç±»æ ‡    
            label_pred=[]
            for i in range(len(np.array(self.label_1_mapping)[...,0])): #æŒ‰è¡Œä¸šç±»æ ‡é‡æ–°ç»„ç»‡æ•°æ®ï¼Œæ¯è¡Œå¯¹åº”è¡Œä¸šç±»æ ‡æ‰€æœ‰çš„èšç±»é¢„æµ‹å€¼
                label_pred.append(pred_label[pred_label[...,-1]==int(np.array(self.label_1_mapping)[...,0][i])])           
            label_cluster_frequency={}
            for p in label_pred:  #æŒ‰è¡Œä¸šç±»æ ‡è®¡ç®—æ¯ç±»æ‰€æœ‰ç‚¹æ‰€å±èšç±»ç°‡çš„æ•°é‡(é¢‘æ•°)
                label_cluster_frequency[(p[...,-1][0])]=[(j,np.sum(p[...,0]==int(j))+1) for j in np.unique(poi_clusteringPred_dict[key]) if j!=-1] #ç‹¬ç«‹æ€§æ£€éªŒå€¼ä¸èƒ½ä¸ºé›¶ï¼Œå› æ­¤å°†æ‰€æœ‰å€¼+1   
            CT_target=list(label_cluster_frequency.keys())
            CT_idx=np.array(list(label_cluster_frequency.values()))
            CT=CT_idx[...,1]  #å»ºç«‹ç”¨äºç‹¬ç«‹æ€§åˆ†æçš„åˆ—è”è¡¨ï¼Œæ¨ªå‘ä¸ºè¡Œä¸šç±»æ‰€å±èšç±»ç°‡é¢‘æ•°ï¼Œçºµå‘ä¸ºè¡Œä¸šç±»æ ‡
            CT_dict[key]=CT
            chi2_test=chi2_contingency(CT)  #åˆ—è”è¡¨çš„å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒ  
            chi_squared_val, p, df,expected_frequencies=chi2_test #æå–å¡æ–¹å€¼gï¼Œpå€¼ï¼Œè‡ªç”±åº¦dofå’Œä¸å…ƒæ•°æ®æ•°ç»„åŒç»´åº¦çš„å¯¹åº”ç†è®ºå€¼ã€‚æ­¤æ¬¡å®éªŒè®¡ç®—p=0.00120633349692ï¼Œå°äº0.05ï¼Œå› æ­¤è¡Œä¸šåˆ†ç±»ä¸èšç±»ç°‡ç›¸å…³ã€‚
            print("èšç±»è·ç¦»ï¼š%s å¡æ–¹å€¼ï¼š%.3f  På€¼ï¼š%.10f  è‡ªç”±åº¦:%d"%(key,chi_squared_val, p, df))
            chi_2Test_dict[key]=chi2_test
        with open(os.path.join(self.save_path,'chi_2Test_dict.pkl'),'wb') as f:
            pickle.dump(chi_2Test_dict,f)
        with open(os.path.join(self.save_path,'POI_contingency_table.pkl'),'wb') as f:
            pickle.dump(CT_dict,f)    

    def POI_structure(self):
        from sklearn import cluster, covariance, manifold
        import pandas as pd
        import numpy as np
        import matplotlib.pyplot as plt
        from matplotlib.collections import LineCollection
        from tqdm import tqdm
        
        from pylab import mpl
        mpl.rcParams['font.sans-serif']=['DengXian'] #è§£å†³ä¸­æ–‡å­—ç¬¦ä¹±ç é—®é¢˜
        
        import warnings
        warnings.filterwarnings("ignore") #å¦‚æœéœ€è¦æŸ¥çœ‹warningæç¤ºï¼Œéœ€è¦æ³¨é‡Šæ‰è¯¥è¡Œ
        '''
        function - POIä¸€çº§è¡Œä¸šåˆ†ç±»çš„ä¸šæ€ç»“æ„.å‚è€ƒå®˜æ–¹æ¡ˆä¾‹Visualizing the stock market structureï¼šhttp://scikit-learn.org/stable/auto_examples/applications/plot_stock_market.html#sphx-glr-auto-examples-applications-plot-stock-market-py
        '''
        savefig_root=os.path.join(self.save_path,'POI_structure')
        if not os.path.exists(savefig_root):
            os.makedirs(savefig_root)
        #A-ä»ç›¸å…³æ€§ä¸­å­¦ä¹ å›¾ç»“æ„ã€‚Learn a graphical structure from the correlations
        edge_model=covariance.GraphicalLassoCV() 
        failed_edge_model_key=[]
        for key in tqdm(CT_dict.keys()):            
            X=CT_dict[key].copy().T  
            X=X/X.std(axis=0)  #æ ‡å‡†åŒ–ã€‚å¯ä»¥è‡ªè¡Œå®éªŒå°è§„æ¨¡æ•°ç»„ï¼ŒæŸ¥çœ‹å˜åŒ–ï¼Œåˆ†æç»“æœï¼Œè·å–ç»“è®ºã€‚
            X[X==np.inf]=0.00000001 #å› ä¸ºå½“èšç±»è·ç¦»éå¸¸å°æ—¶ï¼ŒæŸäº›è¡Œä¸šåˆ†ç±»çš„POIç‚¹å¯èƒ½éƒ½å±äºä¸€ä¸ªç°‡ï¼ˆä¾‹å¦‚å¼‚å¸¸å€¼ä»£è¡¨çš„ç°‡ï¼‰ï¼Œå³åˆ—è”è¡¨çš„æŸä¸€çºµè¡Œå€¼å…¨éƒ¨ç›¸ç­‰ï¼Œæ ‡å‡†å·®åˆ™ä¸º0ï¼Œè€Œ0ä¸èƒ½åšåˆ†æ¯ï¼Œå¦åˆ™ä¼šå¾—å‡ºinfçš„æ­£æ— ç©·å¤§ï¼Œå¯¼è‡´åæ–¹å·®ä¼°è®¡å¤±è´¥ã€‚å› æ­¤æ›¿æ¢0å€¼
            try:
                edge_model.fit(X)            
            except FloatingPointError:
                failed_edge_model_key.append(key)                
            
            #B-ä½¿ç”¨affinity propagationèšç±»ã€‚Cluster using affinity propagation
            _, labels=cluster.affinity_propagation(edge_model.covariance_,random_state=0)
            n_labels=labels.max()            

            #C-We use a dense eigen_solver to achieve reproducibility (arpack is initiated with random vectors that we don't control). In addition, we use a large number of neighbors to capture the large-scale structure.
            node_position_model=manifold.LocallyLinearEmbedding(n_components=2, eigen_solver='dense', n_neighbors=6)
            embedding=node_position_model.fit_transform(X.T).T   
            
            #D-å›¾è¡¨å¯è§†åŒ–poiç©ºé—´åˆ†å¸ƒç»“æ„
            plt.figure(1, facecolor='w', figsize=(10, 8))
            plt.clf()
            ax=plt.axes([0., 0., 1., 1.]) #å¯ä»¥å‚è€ƒå®˜æ–¹ç¤ºä¾‹ç¨‹åº http://matplotlib.org/examples/pylab_examples/axis_equal_demo.html
            plt.axis('off')    

            # Display a graph of the partial correlations/åç›¸å…³åˆ†æ:åœ¨å¤šè¦ç´ æ‰€æ„æˆçš„ç³»ç»Ÿä¸­ï¼Œå½“ç ”ç©¶æŸä¸€ä¸ªè¦ç´ å¯¹å¦ä¸€ä¸ªè¦ç´ çš„å½±å“æˆ–ç›¸å…³ç¨‹åº¦æ—¶ï¼ŒæŠŠå…¶ä»–è¦ç´ çš„å½±å“è§†ä½œå¸¸æ•°ï¼ˆä¿æŒä¸å˜ï¼‰ï¼Œå³æš‚æ—¶ä¸è€ƒè™‘å…¶ä»–è¦ç´ å½±å“ï¼Œå•ç‹¬ç ”ç©¶ä¸¤ä¸ªè¦ç´ ä¹‹é—´çš„ç›¸äº’å…³ç³»çš„å¯†åˆ‡ç¨‹åº¦ï¼Œæ‰€å¾—æ•°å€¼ç»“æœä¸ºåç›¸å…³ç³»æ•°ã€‚åœ¨å¤šå…ƒç›¸å…³åˆ†æä¸­ï¼Œç®€å•ç›¸å…³ç³»æ•°å¯èƒ½ä¸èƒ½å¤ŸçœŸå®çš„åæ˜ å‡ºå˜é‡Xå’ŒYä¹‹é—´çš„ç›¸å…³æ€§ï¼Œå› ä¸ºå˜é‡ä¹‹é—´çš„å…³ç³»å¾ˆå¤æ‚ï¼Œå®ƒä»¬å¯èƒ½å—åˆ°ä¸æ­¢ä¸€ä¸ªå˜é‡çš„å½±å“ã€‚è¿™ä¸ªæ—¶å€™åç›¸å…³ç³»æ•°æ˜¯ä¸€ä¸ªæ›´å¥½çš„é€‰æ‹©ã€‚
            partial_correlations=edge_model.precision_.copy()
            d=1/np.sqrt(np.diag(partial_correlations)) #umpy.diag()è¿”å›ä¸€ä¸ªçŸ©é˜µçš„å¯¹è§’çº¿å…ƒç´ ï¼Œè®¡ç®—è¯¥å…ƒç´ å¹³æ–¹æ ¹çš„å€’æ•°ã€‚
            partial_correlations*=d
            partial_correlations*=d[:, np.newaxis]
            non_zero=(np.abs(np.triu(partial_correlations, k=1)) > 0.02) #np.triu()è¿”å›çŸ©é˜µçš„ä¸Šä¸‰è§’çŸ©é˜µã€‚

            # Plot the nodes using the coordinates of our embedding    
            plt.scatter(embedding[0], embedding[1], s=300*d**2, c=labels,cmap=plt.cm.Spectral) #ç°‡ç±»æ ‡ç”¨äºå®šä¹‰èŠ‚ç‚¹çš„é¢œè‰²ï¼Œé™ç»´åæ•°æ®ä½œä¸ºç‚¹åæ ‡

            # Plot the edges
            start_idx, end_idx=np.where(non_zero)  #numpy.where(condition[, x, y])è¿™é‡Œx,yæ˜¯å¯é€‰å‚æ•°ï¼Œconditionæ˜¯æ¡ä»¶ï¼Œè¿™ä¸‰ä¸ªè¾“å…¥å‚æ•°éƒ½æ˜¯array_likeçš„å½¢å¼ï¼›è€Œä¸”ä¸‰è€…çš„ç»´åº¦ç›¸åŒã€‚å½“conditonçš„æŸä¸ªä½ç½®çš„ä¸ºtrueæ—¶ï¼Œè¾“å‡ºxçš„å¯¹åº”ä½ç½®çš„å…ƒç´ ï¼Œå¦åˆ™é€‰æ‹©yå¯¹åº”ä½ç½®çš„å…ƒç´ ï¼›å¦‚æœåªæœ‰å‚æ•°conditionï¼Œåˆ™å‡½æ•°è¿”å›ä¸ºtrueçš„å…ƒç´ çš„åæ ‡ä½ç½®ä¿¡æ¯ï¼›
            segments=[[embedding[:, start], embedding[:, stop]] for start, stop in zip(start_idx, end_idx)]
            values=np.abs(partial_correlations[non_zero])
            cm=plt.cm.get_cmap('OrRd') #å…·ä½“çš„`matplotlib.colors.Colormap'å®ä¾‹å¯ä»¥æŸ¥çœ‹matplotlibå®˜ç½‘ http://matplotlib.org/users/colormaps.htmlï¼Œæ›¿æ¢ä¸åŒè‰²ç³»
            lc=LineCollection(segments,zorder=0,cmap=cm,norm=plt.Normalize(0, .7 * values.max()))  
            lc.set_array(values) 
            lc.set_linewidths(15 * values) #å®šä¹‰è¾¹ç¼˜çš„å¼ºåº¦ã€‚
            ax.add_collection(lc)

            # Add a label to each node. The challenge here is that we want to position the labels to avoid overlap with other labelsï¼Œæ·»åŠ è¡Œä¸šåˆ†ç±»æ ‡ç­¾ï¼Œå¹¶é¿å…æ ‡ç­¾é‡å ã€‚
            names=[i[-1] for i in self.label_1_mapping]
            for index, (name, label, (x, y)) in enumerate(zip(names, labels, embedding.T)):    
                dx = x - embedding[0]
                dx[index] = 1
                dy = y - embedding[1]
                dy[index] = 1
                this_dx = dx[np.argmin(np.abs(dy))]
                this_dy = dy[np.argmin(np.abs(dx))]
                if this_dx > 0:
                    horizontalalignment = 'left'
                    x = x + .002
                else:
                    horizontalalignment = 'right'
                    x = x - .002
                if this_dy > 0:
                    verticalalignment = 'bottom'
                    y = y + .002
                else:
                    verticalalignment = 'top'
                    y = y - .002
                plt.text(x, y, name, size=10,horizontalalignment=horizontalalignment,verticalalignment=verticalalignment,bbox=dict(facecolor='w',edgecolor=plt.cm.Spectral(label/float(n_labels)),alpha=.6))    
            plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),embedding[0].max() + .10 * embedding[0].ptp(),) #numpy.ptp()æå·®å‡½æ•°è¿”å›æ²¿è½´çš„å€¼çš„èŒƒå›´(æœ€å¤§å€¼-æœ€å°å€¼)ã€‚
            plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),embedding[1].max() + .03 * embedding[1].ptp())              

            plt.savefig(os.path.join(self.save_path,'POI_structure/structure_%s'%key))  #ä¿å­˜æ‰“å°çš„å›¾è¡¨
        print("Failed at key:",failed_edge_model_key)    
        plt.show() #ä»…æ˜¾ç¤ºæœ€åä¸€ä¸ªå›¾è¡¨              
            
import math
eps=list(range(20,520,10)) #è®¾ç½®å¤šä¸ªèšç±»è·ç¦»ï¼Œå•ä½m
min_samples=3
save_path=r'./data/poi_clustering'

#A-æ‰§è¡Œç±»çš„å®ä¾‹åŒ–
batchClustering_DBSCAN=poi_spatial_distribution_structure(poi_dataBunch,eps,min_samples,save_path) 

#B-æ‰§è¡Œèšç±»ï¼Œè®¡ç®—æ—¶é—´ç›¸å¯¹è¾ƒé•¿ï¼Œè®¡ç®—å®Œæˆåï¼Œè®¡ç®—ç»“æœå­˜å‚¨åœ¨å…¨å±€å˜é‡ä¸­ã€‚åˆ¤æ–­è¯¥å˜é‡æ˜¯å¦å­˜åœ¨ï¼Œé¿å…é‡å¤è®¡ç®—
if 'poi_clusteringPred_dict' in globals():pass
else: batchClustering_DBSCAN.clustering_batch_computing() 
#C- ä¿å­˜èšç±»ç»“æœäº.shpæ–‡ä»¶ä¸­,åŠæ‰“å°ä¸€ç»„é¢„è§ˆ
batchClustering_DBSCAN.poi2shp()
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:50<00:00,  1.01s/it]
    

    å®Œæˆè¿ç»­è·ç¦»èšç±»è®¡ç®—ï¼
    A-è¿ç»­è·ç¦»èšç±»ç»“æœä¿å­˜ä¸º.shpæ ¼å¼æ•°æ®ï¼ŒåŠæ‰“å°ä¸€ç»„é¢„è§ˆ
    


    
<a href=""><img src="./imgs/16_05.png" height="auto" width="auto" title="caDesign"></a>
    


å¯¹äºä¸šæ€åˆ†å¸ƒç»“æ„å›¾è¡¨æ‰“å°ï¼Œå…¶ä½ç½®å…³ç³»å¤„ç†å¯ä»¥å‚è€ƒä¸‹å›¾ç†è§£ã€‚

<a href=""><img src="./imgs/16_01.png" height='auto' width=400 title="caDesign">


```python
#D-æ‰§è¡Œç‹¬ç«‹æ€§æ£€éªŒ
batchClustering_DBSCAN.poi_chi_2Test()
#E-POIä¸€çº§è¡Œä¸šåˆ†ç±»çš„ä¸šæ€ç»“æ„
batchClustering_DBSCAN.POI_structure()
```

    èšç±»è·ç¦»ï¼š20_POI å¡æ–¹å€¼ï¼š64230.484  På€¼ï¼š1.0000000000  è‡ªç”±åº¦:149240
    èšç±»è·ç¦»ï¼š30_POI å¡æ–¹å€¼ï¼š87352.339  På€¼ï¼š1.0000000000  è‡ªç”±åº¦:152160
    èšç±»è·ç¦»ï¼š40_POI å¡æ–¹å€¼ï¼š103392.211  På€¼ï¼š1.0000000000  è‡ªç”±åº¦:135280
    èšç±»è·ç¦»ï¼š50_POI å¡æ–¹å€¼ï¼š112294.300  På€¼ï¼š1.0000000000  è‡ªç”±åº¦:118300
    èšç±»è·ç¦»ï¼š60_POI å¡æ–¹å€¼ï¼š113044.157  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:103580
    èšç±»è·ç¦»ï¼š70_POI å¡æ–¹å€¼ï¼š113548.509  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:91780
    èšç±»è·ç¦»ï¼š80_POI å¡æ–¹å€¼ï¼š111007.295  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:81460
    èšç±»è·ç¦»ï¼š90_POI å¡æ–¹å€¼ï¼š108332.737  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:73740
    èšç±»è·ç¦»ï¼š100_POI å¡æ–¹å€¼ï¼š105127.156  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:65940
    èšç±»è·ç¦»ï¼š110_POI å¡æ–¹å€¼ï¼š101796.284  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:59440
    èšç±»è·ç¦»ï¼š120_POI å¡æ–¹å€¼ï¼š98803.125  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:54540
    èšç±»è·ç¦»ï¼š130_POI å¡æ–¹å€¼ï¼š95870.633  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:49900
    èšç±»è·ç¦»ï¼š140_POI å¡æ–¹å€¼ï¼š91418.618  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:46100
    èšç±»è·ç¦»ï¼š150_POI å¡æ–¹å€¼ï¼š88157.942  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:42500
    èšç±»è·ç¦»ï¼š160_POI å¡æ–¹å€¼ï¼š83380.126  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:39400
    èšç±»è·ç¦»ï¼š170_POI å¡æ–¹å€¼ï¼š79456.187  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:36980
    èšç±»è·ç¦»ï¼š180_POI å¡æ–¹å€¼ï¼š74980.026  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:34840
    èšç±»è·ç¦»ï¼š190_POI å¡æ–¹å€¼ï¼š71149.584  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:32840
    èšç±»è·ç¦»ï¼š200_POI å¡æ–¹å€¼ï¼š69800.237  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:30860
    èšç±»è·ç¦»ï¼š210_POI å¡æ–¹å€¼ï¼š66590.862  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:29000
    èšç±»è·ç¦»ï¼š220_POI å¡æ–¹å€¼ï¼š64859.080  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:27900
    èšç±»è·ç¦»ï¼š230_POI å¡æ–¹å€¼ï¼š62218.585  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:26580
    èšç±»è·ç¦»ï¼š240_POI å¡æ–¹å€¼ï¼š60102.417  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:25380
    èšç±»è·ç¦»ï¼š250_POI å¡æ–¹å€¼ï¼š59328.865  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:24140
    èšç±»è·ç¦»ï¼š260_POI å¡æ–¹å€¼ï¼š58001.286  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:23080
    èšç±»è·ç¦»ï¼š270_POI å¡æ–¹å€¼ï¼š56281.658  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:22120
    èšç±»è·ç¦»ï¼š280_POI å¡æ–¹å€¼ï¼š53434.295  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:21080
    èšç±»è·ç¦»ï¼š290_POI å¡æ–¹å€¼ï¼š51931.563  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:19980
    èšç±»è·ç¦»ï¼š300_POI å¡æ–¹å€¼ï¼š50031.810  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:19120
    èšç±»è·ç¦»ï¼š310_POI å¡æ–¹å€¼ï¼š49376.530  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:18480
    èšç±»è·ç¦»ï¼š320_POI å¡æ–¹å€¼ï¼š47995.903  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:17880
    èšç±»è·ç¦»ï¼š330_POI å¡æ–¹å€¼ï¼š46284.856  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:17360
    èšç±»è·ç¦»ï¼š340_POI å¡æ–¹å€¼ï¼š45104.098  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:16940
    èšç±»è·ç¦»ï¼š350_POI å¡æ–¹å€¼ï¼š44128.958  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:16460
    èšç±»è·ç¦»ï¼š360_POI å¡æ–¹å€¼ï¼š42592.969  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:16060
    èšç±»è·ç¦»ï¼š370_POI å¡æ–¹å€¼ï¼š42228.970  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:15600
    èšç±»è·ç¦»ï¼š380_POI å¡æ–¹å€¼ï¼š41839.793  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:15180
    èšç±»è·ç¦»ï¼š390_POI å¡æ–¹å€¼ï¼š41291.175  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:14720
    èšç±»è·ç¦»ï¼š400_POI å¡æ–¹å€¼ï¼š40024.066  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:14220
    èšç±»è·ç¦»ï¼š410_POI å¡æ–¹å€¼ï¼š39405.794  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:13820
    èšç±»è·ç¦»ï¼š420_POI å¡æ–¹å€¼ï¼š38452.403  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:13700
    èšç±»è·ç¦»ï¼š430_POI å¡æ–¹å€¼ï¼š38278.138  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:13300
    èšç±»è·ç¦»ï¼š440_POI å¡æ–¹å€¼ï¼š38051.799  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:12900
    èšç±»è·ç¦»ï¼š450_POI å¡æ–¹å€¼ï¼š36954.747  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:12580
    èšç±»è·ç¦»ï¼š460_POI å¡æ–¹å€¼ï¼š36582.933  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:12220
    èšç±»è·ç¦»ï¼š470_POI å¡æ–¹å€¼ï¼š35636.214  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:11760
    èšç±»è·ç¦»ï¼š480_POI å¡æ–¹å€¼ï¼š35290.098  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:11360
    èšç±»è·ç¦»ï¼š490_POI å¡æ–¹å€¼ï¼š34604.879  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:11060
    èšç±»è·ç¦»ï¼š500_POI å¡æ–¹å€¼ï¼š32641.826  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:10720
    

      0%|          | 0/50 [00:00<?, ?it/s]

    èšç±»è·ç¦»ï¼š510_POI å¡æ–¹å€¼ï¼š32232.697  På€¼ï¼š0.0000000000  è‡ªç”±åº¦:10480
    

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [01:05<00:00,  1.32s/it]

    Failed at key: ['40_POI']
    

    
    


    
<a href=""><img src="./imgs/16_06.png" height="auto" width="auto" title="caDesign"></a>
    


#### 1.3.2 æ›²çº¿æ‹ç‚¹ä¸å…³é”®å±‚çº§
è°ƒå…¥å­˜å‚¨æœ‰èšç±»ä¿¡æ¯çš„.shpæ–‡ä»¶ã€‚


```python
import geopandas as gpd
import util,os

path_root=r'./data/poi_clustering'
poi_clustering_fp=os.path.join(r'./data/poi_clustering','poi_clustering_pred.shp')
poi_clustering=gpd.read_file(poi_clustering_fp)

util.print_html(poi_clustering)
```




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>lat</th>
      <th>lon</th>
      <th>20_POI</th>
      <th>30_POI</th>
      <th>40_POI</th>
      <th>50_POI</th>
      <th>60_POI</th>
      <th>70_POI</th>
      <th>80_POI</th>
      <th>90_POI</th>
      <th>100_POI</th>
      <th>110_POI</th>
      <th>120_POI</th>
      <th>130_POI</th>
      <th>140_POI</th>
      <th>150_POI</th>
      <th>160_POI</th>
      <th>170_POI</th>
      <th>180_POI</th>
      <th>190_POI</th>
      <th>200_POI</th>
      <th>210_POI</th>
      <th>220_POI</th>
      <th>230_POI</th>
      <th>240_POI</th>
      <th>250_POI</th>
      <th>260_POI</th>
      <th>270_POI</th>
      <th>280_POI</th>
      <th>290_POI</th>
      <th>300_POI</th>
      <th>310_POI</th>
      <th>320_POI</th>
      <th>330_POI</th>
      <th>340_POI</th>
      <th>350_POI</th>
      <th>360_POI</th>
      <th>370_POI</th>
      <th>380_POI</th>
      <th>390_POI</th>
      <th>400_POI</th>
      <th>410_POI</th>
      <th>420_POI</th>
      <th>430_POI</th>
      <th>440_POI</th>
      <th>450_POI</th>
      <th>460_POI</th>
      <th>470_POI</th>
      <th>480_POI</th>
      <th>490_POI</th>
      <th>500_POI</th>
      <th>510_POI</th>
      <th>geometry</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>34.113672</td>
      <td>108.614730</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>POINT (108.61473 34.11367)</td>
    </tr>
    <tr>
      <th>1</th>
      <td>34.157196</td>
      <td>108.597683</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>-1</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>POINT (108.59768 34.15720)</td>
    </tr>
    <tr>
      <th>2</th>
      <td>34.106033</td>
      <td>108.630919</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>POINT (108.63092 34.10603)</td>
    </tr>
    <tr>
      <th>3</th>
      <td>34.122130</td>
      <td>108.615176</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>POINT (108.61518 34.12213)</td>
    </tr>
    <tr>
      <th>4</th>
      <td>34.115677</td>
      <td>108.659891</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>3</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>POINT (108.65989 34.11568)</td>
    </tr>
  </tbody>
</table>



* å…³é”®å±‚çº§ä¸€ï¼šè‡ªèº«å…·æœ‰æ˜æ˜¾ç‰¹å¾çš„ç”Ÿæ´»åœˆå±‚çº§

POIç‹¬ç«‹ç‚¹ï¼ˆå¼‚å¸¸å€¼ï¼‰ï¼Œå³ä¸æ»¡è¶³å±‚çº§çš„èšç±»è·ç¦»ï¼Œç›¸å¯¹æ¯”è¾ƒç‹¬ç«‹çš„ç‚¹ï¼Œè®¡ç®—å„å±‚çº§ç‹¬ç«‹ç‚¹æ€»å’Œçš„æ›²çº¿æ‹ç‚¹ï¼Œå…¶å€¼ä¸º120mã€‚è¿›ä¸€æ­¥éªŒè¯å’Œç¡®å®š120mè·ç¦»ä¸‹åŸå¸‚ç”Ÿæ´»åœˆç©ºé—´åˆ†å¸ƒçš„ç‰¹æ®Šæ€§ï¼Œå¯¹ç…§ç™¾åº¦åœ°å›¾ä¿¡æ¯ï¼Œæ ‡æ³¨é¢ç§¯å¤§äº40å…¬é¡·çš„ç»„å›¢83ä¸ª(æ–¹æ³•ç•¥)ã€‚åœ¨è¯¥è·ç¦»ä¸‹èšç±»æ‰€å›¢èšçš„ç»„å›¢å¯ä»¥æ¸…æ™°çš„åæ˜ å„ä¸ªç»„å›¢å› ä¸ºåŸå¸‚åŠŸèƒ½éœ€æ±‚è€Œèšåˆçš„å†…åœ¨æˆå› ï¼Œä¾‹å¦‚ä»¥é«˜æ ¡èšé›†åŒºä¸ºç‰¹å¾çš„å›¢èšï¼ŒåŒ…æ‹¬è¥¿å—äºŒç¯ã€ä¸œå—äºŒç¯ã€é•¿å®‰åŒºåŒ—ã€é•¿å®‰åŒºå—ã€é•¿å®‰åŒºè¥¿ã€é•¿å®‰å—è·¯ã€å¤§æ˜å®«ã€é›å¡”åŒ—è·¯ã€ä¸´æ½¼ã€çæ¡¥åŒºç­‰ï¼›éƒ¨åˆ†é«˜æ ¡è¾ƒä¸ºç‹¬ç«‹ï¼Œè‡ªèº«ä¸å‘¨è¾¹ç¤¾åŒºå½¢æˆç»„å›¢ä¾‹å¦‚è¥¿è—æ°‘æ—å¤§å­¦ã€é™•è¥¿å·¥ä¸šèŒä¸šæŠ€æœ¯å­¦é™¢ç­‰ï¼›ä»¥åŒºã€å¿é•‡ã€ä¹¡ä¸ºç‰¹å¾çš„å›¢èšï¼Œä¾‹å¦‚é„ é‚‘åŒºã€çæ¡¥åŒºã€é«˜é™µåŒºã€ä¸‰åŸå¿ã€è“ç”°å¿ã€å¤§ç‹é•‡ã€æ–°ä¸°é•‡ã€æ–—é—¨é•‡ã€ä¸œé£æ‘ã€åŒ—è¾°æ‘ã€ä¸œä¸‰çˆ»æ‘ç­‰ï¼›ä»¥åŠä»¥æœºåœºã€ç«è½¦ç«™ã€å†å²é—å€ç­‰æ™¯ç‚¹ã€ç”µå­åŸã€æ‰¹å‘å¸‚åœºã€å»ºæå¸‚åœºç­‰å›¢èšçš„ç»„å›¢ã€‚å› ä¸º120mè·ç¦»èšç±»åŸå¸‚å±‚çº§çš„ç‰¹å¾å¯ä»¥å¾ˆå¥½æŒ‰ç…§åŒºåŸŸç‰¹ç‚¹å›¢èšå½¢æˆç”Ÿæ´»åœˆï¼Œå› æ­¤å¯ä»¥ä¸ºåŸå¸‚è¡—åŒºçš„ç ”ç©¶æä¾›å¯ä»¥å‚ç…§çš„ç ”ç©¶è¾¹ç•Œï¼Œé¿å…å•çº¯ç‰©ç†åœ°å—çš„åˆ’åˆ†ã€‚


```python
from data_generator import DataGenerator
from knee_locator import KneeLocator

poi_columns=list(poi_clustering.columns)[2:-1]
poi_outlier_count=[(poi_clustering[field]==-1).sum() for field in  poi_columns]

def kneed_lineGraph(x,y):
    import matplotlib.pyplot as plt
    '''
    function - ç»˜åˆ¶æŠ˜çº¿å›¾ï¼ŒåŠå…¶æ‹ç‚¹ã€‚éœ€è°ƒç”¨kneedåº“çš„KneeLocatorï¼ŒåŠDataGeneratoræ–‡ä»¶
    
    Paras:
    x - æ¨ªåæ ‡ï¼Œç”¨äºæ¨ªè½´æ ‡ç­¾
    y - çºµåæ ‡ï¼Œç”¨äºè®¡ç®—æ‹ç‚¹    
    '''
    #å¦‚æœè°ƒæ•´å›¾è¡¨æ ·å¼ï¼Œéœ€è°ƒæ•´knee_locatoræ–‡ä»¶ä¸­çš„plot_kneeï¼ˆï¼‰å‡½æ•°ç›¸å…³å‚æ•°
    kneedle=KneeLocator(x, y, curve='convex', direction='decreasing')
    print('æ›²çº¿æ‹ç‚¹ï¼ˆå‡¸ï¼‰ï¼š',round(kneedle.knee, 3))
    print('æ›²çº¿æ‹ç‚¹ï¼ˆå‡¹ï¼‰ï¼š',round(kneedle.elbow, 3))
    kneedle.plot_knee(figsize=(8,8))
    
outlier_x=[int(i.split('_')[0]) for i in poi_columns] 
outlier_y=poi_outlier_count
kneed_lineGraph(x=outlier_x,y=outlier_y)    
```

    æ›²çº¿æ‹ç‚¹ï¼ˆå‡¸ï¼‰ï¼š 120
    æ›²çº¿æ‹ç‚¹ï¼ˆå‡¹ï¼‰ï¼š 120
    


    
<a href=""><img src="./imgs/16_07.png" height="auto" width="auto" title="caDesign"></a>
    



```python
import geopandas as gpd
import matplotlib.pyplot as plt

fig, ax=plt.subplots(figsize =(15, 10))
poi_clustering.plot(column=poi_clustering['120_POI'],markersize=1,figsize=(15,15),ax=ax,cmap='flag') 
ax.set_title("clustering distance 120m", fontsize=20)
```




    Text(0.5, 1.0, 'clustering distance 120m')




    
<a href=""><img src="./imgs/16_08.png" height="auto" width="auto" title="caDesign"></a>
    


* å…³é”®å±‚çº§äºŒï¼šå¤„äºç›¸å¯¹ç¨³å®šçŠ¶æ€ä¸‹çš„åŸå¸‚ç”Ÿæ´»åœˆ

è®¡ç®—æ¯ä¸€å±‚çº§èšç±»æ•°é‡ï¼Œç»˜åˆ¶æ›²çº¿ä¸è®¡ç®—æ‹ç‚¹å€¼ä¸º130mã€‚ä¸ºäº†æ‹ç‚¹è®¡ç®—ç§»é™¤äº†èšç±»è·ç¦»20mçš„å±‚çº§ï¼Œå› ä¸ºè¯¥å±‚çº§çš„èšç±»æ•°é‡å°äº30må±‚çº§çš„æ•°é‡ï¼Œæ›²çº¿å‡ºç°è½¬æŠ˜ï¼Œæ‹ç‚¹è®¡ç®—ä¼šå‡ºé”™ã€‚åœ¨è¿ç»­èšç±»è¿‡ç¨‹ä¸­ï¼Œéšç€è·ç¦»çš„å¢åŠ ï¼Œé‚»è¿‘çš„ç‚¹å¼€å§‹é›†èšï¼Œå½¢æˆç»„å›¢çš„æ•°é‡ï¼Œå³èšç±»æ€»æ•°å¼€å§‹é€æ¸å‡å°‘ã€‚è®¡ç®—POIèšç±»æ€»æ•°å˜åŒ–æœ€å¿«çš„ä½ç½®ï¼Œå³è®¡ç®—æ‹Ÿåˆæ›²çº¿çš„æœ€å¤§æ›²ç‡ï¼Œå…¶å¯¹åº”çš„è·ç¦»å€¼ä¸º130mã€‚ä»£è¡¨çš„å«ä¹‰ä¸ºè·ç¦»130mä¹‹å‰é‚»è¿‘çš„ç»„å›¢æˆ–å•ç‹¬çš„POIç‚¹è¾ƒä¸ºè¿…é€Ÿçš„é›†èšä¸ºè¾ƒå¤§çš„ç»„å›¢ï¼Œè€Œè¯¥è·ç¦»ä¹‹åçš„é›†èšè¿‡ç¨‹åˆ™ç›¸å¯¹ç¼“æ…¢ï¼Œå„ä¸ªç»„å›¢ä¹‹é—´çš„è”ç³»ç›¸å¯¹è¾ƒå¼±ï¼Œå› æ­¤130mè·ç¦»èšç±»ä¸‹çš„å±‚çº§æ˜¯è¡¨å¾åŸå¸‚ç©ºé—´ç»“æ„çš„åˆä¸€ä¸ªå…³é”®ç‚¹ã€‚130må±‚çº§çš„èšç±»ç»„å›¢åæ˜ äº†åŸå¸‚ç¤¾ä¼šç©ºé—´ç»“æ„ç›¸å¯¹ç¨³å®šçš„åŸºæœ¬æ ¼å±€ã€‚åœ¨åˆ†å¸ƒç‰¹ç‚¹ä¸Šå‘ˆç°å¤§é›†èšã€å°åˆ†æ•£çš„æ ¼å±€ã€‚

å…³é”®å±‚çº§ä¸€å’ŒäºŒéå¸¸çš„æ¥è¿‘ï¼Œæ˜¯å¦èƒ½å¤Ÿè¯´æ˜ç‹¬ç«‹ç‚¹çš„å‡å°‘è¶‹åŠ¿ä¸èšç±»æ€»æ•°å˜åŒ–è¶‹åŠ¿ä¿æŒä¸€è‡´ï¼Ÿ


```python
import numpy as np
poi_cluster_count=[np.unique(poi_clustering[field]).sum() for field in  poi_columns]

cutoff=1
cluster_x=[int(i.split('_')[0]) for i in poi_columns][cutoff:]
cluster_y=poi_cluster_count[cutoff:]
kneed_lineGraph(x=cluster_x,y=cluster_y)   
```

    æ›²çº¿æ‹ç‚¹ï¼ˆå‡¸ï¼‰ï¼š 130
    æ›²çº¿æ‹ç‚¹ï¼ˆå‡¹ï¼‰ï¼š 130
    


    
<a href=""><img src="./imgs/16_09.png" height="auto" width="auto" title="caDesign"></a>
    


* å…³é”®å±‚çº§ä¸‰ï¼šåŸå¸‚æœ€å¤§ç”Ÿæ´»åœˆçš„å±‚çº§ä¸è¾¹ç¼˜

åŸå¸‚å‘å±•è¾¹ç¼˜çš„ç•Œå®šæ˜¯åŸå¸‚ç ”ç©¶çš„é‡è¦å†…å®¹ä¹‹ä¸€ï¼Œæ˜¯ç¡®å®šæœªæ¥åŸå¸‚å¢é•¿è¾¹ç•Œçš„é‡è¦ä¾æ®ï¼ŒåŸºäºPOIçš„åŸå¸‚ç¤¾ä¼šç©ºé—´è¾¹ç¼˜çš„ç¡®å®šåˆ™åæ˜ äº†æœªæ¥åŸå¸‚å¢é•¿çš„æ ¸å¿ƒé©±åŠ¨åŠ›æ‰€åœ¨ã€‚å¯¹POIæ‰€åæ˜ çš„åŸå¸‚è¾¹ç¼˜çš„ç•Œå®šç”±æ¯ä¸€å±‚çº§æœ€å¤§ç°‡ç±»ç¡®å®šï¼ˆæœ€å¤§é¢‘æ•°ï¼‰ï¼Œå„å±‚çº§æœ€å¤§ç°‡ç±»çš„å˜åŒ–åæ˜ äº†ç°‡ç±»è¾¹ç¼˜æ‰©å¼ çš„ç¨‹åº¦ï¼Œç”±ä¸‹è¿°å›¾è¡¨å¯ä»¥åˆæ­¥åˆ¤æ–­å‡ºæœ‰5ä¸ªè¾ƒå¤§çš„è·³å˜ç‚¹ï¼Œå³åœ¨æ¯ä¸€ä¸ªè·³å˜ç‚¹ä¹‹å‰çš„å±‚çº§éƒ½æ˜¯åœ¨ç¼“æ­¥å¢åŠ ï¼Œé€æ­¥æ‰©å±•å„è‡ªçš„ç°‡ï¼ˆç”Ÿæ´»åœˆï¼‰ï¼Œåˆ°è·³å˜ç‚¹ä½ç½®å‘ç”Ÿäº†è¾ƒå¤§çš„èåˆï¼Œå³èåˆå‰åçš„ç”Ÿæ´»åœˆèŒƒå›´å‘ç”Ÿäº†è¾ƒå¤§çš„å˜åŒ–ï¼Œè¿™ä¸ªå˜åŒ–çš„åŒºåŸŸå¯¹åŸå¸‚çš„å‘å±•ç ”ç©¶å…·æœ‰é‡è¦æ„ä¹‰ï¼Œæ˜¯åˆ†æç”Ÿæ´»åœˆæ‰©å¼ æˆ–è€…éš”æ–­åŸå› çš„å…³é”®ç‚¹ã€‚


```python
poi_frequency=[poi_clustering[field].value_counts().drop(index=-1) for field in  poi_columns]    #.drop(index=-1)
poi_frequency_max=[i.max() for i in poi_frequency]
poi_frequency_difference=[poi_frequency_max[i+1]-poi_frequency_max[i] for i in range(len(poi_frequency_max)-1)]

x_clusteringDistance=[int(i.split('_')[0]) for i in poi_columns]
x_clusteringDistance_diff=['%s-%s'%(x_clusteringDistance[i+1],x_clusteringDistance[i]) for i in range(len(x_clusteringDistance)-1)]

import matplotlib.pyplot as plt
from pylab import mpl
mpl.rcParams['font.sans-serif']=['DengXian'] #è§£å†³ä¸­æ–‡å­—ç¬¦ä¹±ç é—®é¢˜ #è®¾ç½®å›¾è¡¨æ–‡å­—æ ·å¼
font={'family' : 'STXihei',
      'weight' : 'normal',
      'size'   : 12,}
             
plt.figure(figsize=(12, 12))
plt.plot(x_clusteringDistance_diff,poi_frequency_difference,'ro-',label="maximum frequency variation")
plt.xlabel('clustering distance',font)
plt.ylabel('maximum frequency diff',font)
plt.tick_params(labelsize=12)
plt.legend(prop=font)       
plt.xticks(rotation=90)
plt.show()
```

    findfont: Font family ['STXihei'] not found. Falling back to DejaVu Sans.
    


    
<a href=""><img src="./imgs/16_10.png" height="auto" width="auto" title="caDesign"></a>
    



```python
fig, axs=plt.subplots(1,5,figsize =(30, 15))
poiCluster_selections=['140_POI','180_POI','230_POI','250_POI','330_POI']
i=0
for field in poiCluster_selections:    
    poi_clustering.plot(column=poi_clustering[field],markersize=1,ax=axs[i],cmap='flag') 
    axs[i].set(title=field)
    i+=1
```


    
<a href=""><img src="./imgs/16_11.png" height="auto" width="auto" title="caDesign"></a>
    


#### 1.3.3 ä¸šæ€ç»“æ„å›¾è¡¨æ‹¼åˆï¼Œç”Ÿæ´»åœˆçš„ä¸šæ€ç»“æ„ç©ºé—´å˜åŒ–ç‰¹å¾ã€‚
åœ¨POIç©ºé—´ç»“æ„åˆ†æè®¡ç®—ä¸­ï¼Œå¯¹äºPOIä¸šæ€ç»“æ„çš„å›¾è¡¨å•ç‹¬ä¿å­˜åœ¨æ–‡ä»¶å¤¹ä¸­ï¼Œåœ¨è®ºæ–‡å†™ä½œè¿‡ç¨‹ä¸­é€šå¸¸éœ€è¦å°†å…¶æ‹¼åˆæˆä¸€å¼ å¤§å›¾ç”¨ä½œè®ºæ–‡çš„å›¾è¡¨è¯´æ˜ã€‚ä¸‹è¿°å®šä¹‰çš„ç±»åŒ…å«æŒ‰ç…§å›¾åƒæ–‡ä»¶åä¸­çš„æ•°å­—æ’åºæ–‡ä»¶ï¼Œè¯»å–å’Œå‹ç¼©å›¾åƒä¸ºæ•°ç»„æ ¼å¼ï¼Œå»ºç«‹æ–‡ä»¶å¤¹ï¼Œæ‹¼åˆå›¾åƒä¸æ˜¾ç¤ºï¼Œä»¥åŠä¿å­˜å›¾åƒç­‰åŠŸèƒ½ã€‚


```python
class combine_pics:
    def __init__(self,save_path,file_path,n_cols,scale,space=1,pad_val=255,figsize=(20,10)):
        import os,math
        self.save_path=save_path
        self.file_path=file_path        
        self.scale=scale
        self.n_cols=n_cols
        self.n_rows=math.ceil(len(os.listdir(self.file_path))/self.n_cols) 
        self.scale=space
        self.pad_val=pad_val
        self.space=space
        self.figsize=figsize
           
    def file_sorting(self):      
        import re,math,os
        '''
        function - æ–¹æ³•ç”¨äºè¿”å›æŒ‡å®šçš„æ–‡ä»¶å¤¹åŒ…å«çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„åå­—çš„åˆ—è¡¨ï¼ŒæŒ‰å­—æ¯-æ•°å­—é¡ºåºã€‚å› æ­¤æ•°æ®æ–‡ä»¶å†…ä¸è¦åŒ…å«å­æ–‡ä»¶å¤¹ï¼Œå¦åˆ™è¯¥æ–‡ä»¶å¤¹åç§°ä¹Ÿä¼šè¢«è¯»å–ã€‚æ–‡ä»¶åçš„æ ¼å¼ä¸ºï¼š'xx_100_xx.extension'
        '''
        dirs_files=os.listdir(self.file_path)
        dirs_files.sort()
        pattern=re.compile(r'[_](.*?)[_]', re.S) #re.compile(r'[_](.*?)[.]', re.S)
        fn_numExtraction=[(int(re.findall(pattern, fName)[0]),fName) for fName in dirs_files]
        #æå–æ–‡ä»¶åä¸­çš„æ•°å­—ï¼Œå³èšç±»è·ç¦»ã€‚å¹¶å¯¹åº”æ–‡ä»¶å
        fn_sort=sorted(fn_numExtraction) 
        fn_sorted=[i[1] for i in fn_sort]
        image_names=[] #å­˜å‚¨çš„ä¸ºå›¾ç‰‡çš„è·¯å¾„å
        for dir_file in fn_sorted:
            image_path=os.path.join(self.file_path, dir_file)
            if image_path.endswith('.png'):
                image_names.append(image_path)               
        q_imgs_paths=image_names[0:self.n_rows*self.n_cols] #ä¿è¯æå–çš„å›¾ç‰‡æ•°é‡ä¸æ‰€é…ç½®çš„n_rows*n_colsæ•°é‡åŒ    
        return q_imgs_paths
    
    def read_compress_imgs(self,imgs_fp):
        from PIL import Image
        import numpy as np
        '''
        function - è¯»å–ä¸å‹ç¼©å›¾ç‰‡
        
        Paras:
        imgs_fp - å›¾åƒè·¯å¾„åˆ—è¡¨
        '''
        imgs=[] #å­˜å‚¨çš„ä¸ºè¯»å–çš„å›¾ç‰‡æ•°æ®
        for img_fp in imgs_fp:
            img_array=Image.open(img_fp.rstrip())            
            img_resize=img_array.resize([int(self.scale * s) for s in img_array.size] ) #ä¼ å…¥å›¾åƒçš„æ•°ç»„ï¼Œè°ƒæ•´å›¾ç‰‡å¤§å° 
            img_trans=np.asarray(img_resize).transpose(2, 0, 1) #è½¬ç½®
            if (img_trans.shape[0] is not 3):
                img_trans=img_trans[0:3,:,:]
            imgs.append(img_trans)
            
        return imgs
    
    def make_dir(self):
        import os
        '''
        function - å»ºç«‹æ–‡ä»¶å¤¹ï¼Œç”¨äºå­˜å‚¨æ‹¼åˆçš„å›¾ç‰‡
        '''
        savefig_root=os.path.join(self.save_path,'imgs_combination')
        if os.path.exists(savefig_root):
            print("File exists!")
        else:
            os.makedirs(savefig_root)     
        return savefig_root
    
    def imgs_combination(self,imgs):
        import numpy as np
        import matplotlib.pyplot as plt
        import matplotlib.image as mpimg
        '''
        function - æ‹¼åˆå›¾ç‰‡
        '''
        #assert æ–­è¨€æ˜¯å£°æ˜è¯­å¥çœŸå‡çš„å¸ƒå°”åˆ¤æ–­ï¼Œå¦‚æœå€¼ä¸ºçœŸåˆ™æ‰§è¡Œç¨‹åºï¼Œå¦åˆ™ç»ˆæ­¢ç¨‹åºï¼Œé¿å…è¿è¡Œè¿‡ç¨‹ä¸­ç¨‹åºå´©æºƒ
        assert (imgs[0].ndim == 3) and (imgs[0].shape[0] == 3)
        assert len(imgs) <= self.n_rows * self.n_cols
        h, w=imgs[0].shape[1:]
        H=h * self.n_rows + self.space * (self.n_rows - 1)
        W=w * self.n_cols + self.space * (self.n_cols - 1)
        if isinstance(self.pad_val, np.ndarray): #isinstanceï¼ˆobjectï¼Œtypeï¼‰ç”¨äºåˆ¤æ–­ä¸€ä¸ªå¯¹è±¡æ˜¯å¦æ˜¯ä¸€ä¸ªå·²çŸ¥ç±»å‹
            self.pad_val=self.pad_val.flatten()[:, np.newaxis, np.newaxis]
        ret_img=(np.ones([3, H, W]) * self.pad_val).astype(imgs[0].dtype)
        for n, img in enumerate(imgs):
            r=n // self.n_cols
            c=n % self.n_cols
            h1=r * (h + self.space)
            h2=r * (h + self.space) + h
            w1=c * (w + self.space)
            w2=c * (w + self.space) + w
            ret_img[:, h1:h2, w1:w2] = img
        plt.figure(figsize=self.figsize)
        plt.imshow(ret_img.transpose(1,2,0))
        
        return ret_img
    
    def image_save(self,img,savefig_root):
        from PIL import Image
        import os
        '''
        function -ä¿å­˜å›¾åƒ
        '''
        if (img.shape[2] is not 3):
            img=img.transpose(1,2,0)
        Image.fromarray(img).save(os.path.join(savefig_root,'img_combination.jpg')) 
        
poiStructure_fp=r'./data/poi_clustering/POI_structure'
poiStructure_savePath=r'./data/poi_clustering'     
n_cols=10
scale=0.5
space=3
pad_val=255
figsize=(30,10)
combinePics=combine_pics(poiStructure_savePath,poiStructure_fp,n_cols,scale,space,pad_val,figsize)
q_imgs_paths=combinePics.file_sorting()
imgs_compressed=combinePics.read_compress_imgs(q_imgs_paths)
savefig_root=combinePics.make_dir()
ret_img=combinePics.imgs_combination(imgs_compressed,)
combinePics.image_save(ret_img,savefig_root)
```

    <>:48: SyntaxWarning: "is not" with a literal. Did you mean "!="?
    <>:101: SyntaxWarning: "is not" with a literal. Did you mean "!="?
    <>:48: SyntaxWarning: "is not" with a literal. Did you mean "!="?
    <>:101: SyntaxWarning: "is not" with a literal. Did you mean "!="?
    <ipython-input-25-625a9a600d36>:48: SyntaxWarning: "is not" with a literal. Did you mean "!="?
      if (img_trans.shape[0] is not 3):
    <ipython-input-25-625a9a600d36>:101: SyntaxWarning: "is not" with a literal. Did you mean "!="?
      if (img.shape[2] is not 3):
    

    File exists!
    


    
<a href=""><img src="./imgs/16_12.png" height="auto" width="auto" title="caDesign"></a>
    


#### 1.3.4 ä¿¡æ¯ç†µå’Œå‡è¡¡åº¦åˆ†æ
è®¡ç®—50å±‚çº§æ¯ä¸€å±‚çº§èšç±»åå„ç°‡çš„å‡è¡¡åº¦ï¼Œå¯ä»¥åˆ†æå…³é”®å±‚çº§ä¸‹å„ç”Ÿæ´»åœˆå‡è¡¡åº¦çš„å˜åŒ–ï¼Œæ¯”è¾ƒåŒä¸€å±‚çº§ç”Ÿæ´»åœˆä¹‹é—´è¡Œä¸šç±»åˆ«ç©ºé—´åˆ†å¸ƒçš„å‡è´¨æ€§ï¼Œè¾ƒé«˜çš„å‡è¡¡åº¦å…·æœ‰è¾ƒé«˜çš„å‡è´¨æ€§ã€‚é€šè¿‡å¯¹å‡è¡¡åº¦çš„è®¡ç®—ï¼Œå¯ä»¥ä»è¡Œä¸šç±»å‹æä¾›çš„æœåŠ¡æ‰€èƒ½æ»¡è¶³äººä»¬çš„ç”Ÿæ´»éœ€æ±‚æ–¹é¢ï¼Œæ¥æ¢ç´¢ç”Ÿæ´»åœˆä¹‹é—´è”ç³»çš„ç´§å¯†ç¨‹åº¦ã€‚


```python
import pickle
dataset_bunch_fp=r'./data/poi_clustering/POI_dataset_bunch.pkl'
with open(dataset_bunch_fp,'rb') as f:
    dataset_bunch=pickle.load(f)
poi_label=dataset_bunch.target[:,0]        
poi_columns=list(poi_clustering.columns)[2:-1]

def equilibriumDegree_hierarchy(poi_clustering,poi_columns,poi_label):
    from collections import Counter
    import math
    import pandas as pd
    from tqdm import tqdm
    '''
    function - è®¡ç®—POIçš„å‡è¡¡éƒ½
    
    Paras:
    poi_clustering - èšç±»ä¿¡æ¯ï¼ŒDataFrame
    poi_columns - èšç±»å±‚çº§ï¼Œpoi_clusteringåˆ—å
    poi_label - POIç‚¹å¯¹åº”çš„è¡Œä¸šç±»æ ‡
    '''
    equilibrium_degree_hierarchy={}
    for dist in tqdm(poi_columns):
        clusterID_poiID={}
        poi_cluster=poi_clustering[dist]
        for idx in poi_cluster.index:
            clusterID_poiID.setdefault(poi_cluster.loc[idx],[]).append(poi_label[idx]) #ç°‡ä¸ºé”®ï¼Œå€¼ä¸ºæ‰€æœ‰è¯¥ç°‡ä¸‹çš„poiç‚¹çš„è¡Œä¸šç±»æ ‡ï¼ŒåŒä¸€è¡Œä¸šç±»æ ‡ä¼šå¤šæ¬¡å‡ºç°ï¼Œæœ‰å‡ºç°çš„å¤šå°‘ï¼Œèƒ½å¤ŸçŸ¥é“è¯¥ç°‡ä¸­é‚£äº›è¡Œä¸šå æ®ä¼˜åŠ¿ã€‚
        cluster_size={}
        poiClassi_frequency={}
        for key in clusterID_poiID.keys():
            cluster_size[key]=len(clusterID_poiID[key])
            poiClassi_frequency[key]=Counter(clusterID_poiID[key]) #ä½¿ç”¨collectionsåº“Counterå¯¹è±¡ï¼Œç”¨äºè¡Œä¸šç±»é¢‘æ•°è®¡ç®—
        equilibrium_degree={}
        for key in poiClassi_frequency.keys():
            s_entropy=0.0
            sum_v=cluster_size[key]
            for i in poiClassi_frequency[key].keys():
                fre_percentage=poiClassi_frequency[key][i]*1.000/sum_v #è®¡ç®—ç°‡è¡Œä¸šç±»é¢‘æ•°å æ€»æ•°çš„ç™¾åˆ†æ¯”
                s_entropy-=fre_percentage*math.log(fre_percentage) #è®¡ç®—ä¿¡æ¯ç†µ
            category_num=len(poiClassi_frequency[key].keys()) #è·å–è¡Œä¸šç±»æ•°é‡
            max_entropy=math.log(category_num) #logNå³ä¸ºæœ€å¤§ç†µå€¼
            if max_entropy==0: #æ’é™¤ç‰¹æ®Šæƒ…å†µï¼Œå¹¶ç»™å®šä¸€ä¸ªå›ºå®šå€¼æ ‡è¯†
                equilibrium_degree[key]=0.01
            else:
                frank_e=s_entropy/max_entropy
                equilibrium_degree[key]=frank_e

        equilibrium_degree_hierarchy[dist]=equilibrium_degree
    equilibrium_degree_hierarchy_df=pd.DataFrame.from_dict(equilibrium_degree_hierarchy)   
    return equilibrium_degree_hierarchy_df
    
equilibrium_degree_hierarchy_df=equilibriumDegree_hierarchy(poi_clustering,poi_columns,poi_label)
import util
util.print_html(equilibrium_degree_hierarchy_df)
```

    100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:35<00:00,  1.42it/s]
    




<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>20_POI</th>
      <th>30_POI</th>
      <th>40_POI</th>
      <th>50_POI</th>
      <th>60_POI</th>
      <th>70_POI</th>
      <th>80_POI</th>
      <th>90_POI</th>
      <th>100_POI</th>
      <th>110_POI</th>
      <th>120_POI</th>
      <th>130_POI</th>
      <th>140_POI</th>
      <th>150_POI</th>
      <th>160_POI</th>
      <th>170_POI</th>
      <th>180_POI</th>
      <th>190_POI</th>
      <th>200_POI</th>
      <th>210_POI</th>
      <th>220_POI</th>
      <th>230_POI</th>
      <th>240_POI</th>
      <th>250_POI</th>
      <th>260_POI</th>
      <th>270_POI</th>
      <th>280_POI</th>
      <th>290_POI</th>
      <th>300_POI</th>
      <th>310_POI</th>
      <th>320_POI</th>
      <th>330_POI</th>
      <th>340_POI</th>
      <th>350_POI</th>
      <th>360_POI</th>
      <th>370_POI</th>
      <th>380_POI</th>
      <th>390_POI</th>
      <th>400_POI</th>
      <th>410_POI</th>
      <th>420_POI</th>
      <th>430_POI</th>
      <th>440_POI</th>
      <th>450_POI</th>
      <th>460_POI</th>
      <th>470_POI</th>
      <th>480_POI</th>
      <th>490_POI</th>
      <th>500_POI</th>
      <th>510_POI</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.010000</td>
      <td>0.854991</td>
      <td>0.875346</td>
      <td>0.903017</td>
      <td>0.903606</td>
      <td>0.919217</td>
      <td>0.918730</td>
      <td>0.918136</td>
      <td>0.918302</td>
      <td>0.919271</td>
      <td>0.919692</td>
      <td>0.919999</td>
      <td>0.920695</td>
      <td>0.920741</td>
      <td>0.921572</td>
      <td>0.921516</td>
      <td>0.921455</td>
      <td>0.921396</td>
      <td>0.921393</td>
      <td>0.921382</td>
      <td>0.921373</td>
      <td>0.921316</td>
      <td>0.921228</td>
      <td>0.921402</td>
      <td>0.921402</td>
      <td>0.921507</td>
      <td>0.921458</td>
      <td>0.921468</td>
      <td>0.919887</td>
      <td>0.905290</td>
      <td>0.905696</td>
      <td>0.905703</td>
      <td>0.905622</td>
      <td>0.905542</td>
      <td>0.905604</td>
      <td>0.905610</td>
      <td>0.905610</td>
      <td>0.905610</td>
      <td>0.905610</td>
      <td>0.905610</td>
      <td>0.905572</td>
      <td>0.905572</td>
      <td>0.905572</td>
      <td>0.905572</td>
      <td>0.905572</td>
      <td>0.906576</td>
      <td>0.906450</td>
      <td>0.906475</td>
      <td>0.906468</td>
      <td>0.906468</td>
    </tr>
    <tr>
      <th>-1</th>
      <td>0.912976</td>
      <td>0.913930</td>
      <td>0.913070</td>
      <td>0.923103</td>
      <td>0.917445</td>
      <td>0.911094</td>
      <td>0.904283</td>
      <td>0.897303</td>
      <td>0.889472</td>
      <td>0.882779</td>
      <td>0.874531</td>
      <td>0.864786</td>
      <td>0.855678</td>
      <td>0.850499</td>
      <td>0.844647</td>
      <td>0.852288</td>
      <td>0.847269</td>
      <td>0.841509</td>
      <td>0.837111</td>
      <td>0.833436</td>
      <td>0.827045</td>
      <td>0.822733</td>
      <td>0.830811</td>
      <td>0.829283</td>
      <td>0.826418</td>
      <td>0.822946</td>
      <td>0.820354</td>
      <td>0.818624</td>
      <td>0.815331</td>
      <td>0.813362</td>
      <td>0.807977</td>
      <td>0.807018</td>
      <td>0.805189</td>
      <td>0.799374</td>
      <td>0.800022</td>
      <td>0.796108</td>
      <td>0.796055</td>
      <td>0.797863</td>
      <td>0.795128</td>
      <td>0.795853</td>
      <td>0.794717</td>
      <td>0.797726</td>
      <td>0.797925</td>
      <td>0.791368</td>
      <td>0.787268</td>
      <td>0.786212</td>
      <td>0.790168</td>
      <td>0.788775</td>
      <td>0.788937</td>
      <td>0.781299</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.000000</td>
      <td>0.970951</td>
      <td>0.832661</td>
      <td>0.839194</td>
      <td>0.854842</td>
      <td>0.867522</td>
      <td>0.895771</td>
      <td>0.914686</td>
      <td>0.911814</td>
      <td>0.784581</td>
      <td>0.797796</td>
      <td>0.861329</td>
      <td>0.856614</td>
      <td>0.854796</td>
      <td>0.854221</td>
      <td>0.854221</td>
      <td>0.851926</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.010000</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.650022</td>
      <td>0.724834</td>
      <td>0.724834</td>
      <td>0.724834</td>
      <td>0.724834</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.913865</td>
      <td>0.932935</td>
      <td>0.876046</td>
      <td>0.871304</td>
      <td>0.871304</td>
      <td>1.000000</td>
      <td>0.783782</td>
      <td>0.783782</td>
      <td>0.783782</td>
      <td>0.897460</td>
      <td>0.897460</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.838913</td>
      <td>0.838913</td>
      <td>0.839346</td>
      <td>0.809641</td>
      <td>0.826245</td>
      <td>0.826245</td>
      <td>0.827911</td>
      <td>0.828219</td>
      <td>0.820660</td>
      <td>0.820660</td>
      <td>0.810924</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.903989</td>
      <td>0.903989</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.897460</td>
      <td>0.897460</td>
      <td>0.897460</td>
      <td>0.897460</td>
      <td>0.866911</td>
      <td>0.866911</td>
      <td>0.852778</td>
      <td>0.852778</td>
      <td>0.852778</td>
      <td>0.843752</td>
      <td>0.843752</td>
      <td>0.859386</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.909072</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.886710</td>
      <td>0.757791</td>
      <td>0.757791</td>
      <td>0.967722</td>
      <td>0.967722</td>
      <td>0.967722</td>
      <td>0.967722</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.941184</td>
      <td>0.941184</td>
      <td>0.941184</td>
      <td>0.941184</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
      <td>0.962961</td>
    </tr>
  </tbody>
</table>




```python
equilibrium_hierarchy=poi_clustering.replace({hierarchy:equilibrium_degree_hierarchy_df[hierarchy].to_dict() for hierarchy in poi_columns})
print("å®Œæˆå‡è¡¡åº¦å€¼æ›¿æ¢ã€‚")
```

    å®Œæˆå‡è¡¡åº¦å€¼æ›¿æ¢ã€‚
    


```python
equilibrium_hierarchy.plot(column=equilibrium_hierarchy['140_POI'],markersize=1,figsize=(20,10),cmap='Reds',legend=True) 
```




    <AxesSubplot:>




    
<a href=""><img src="./imgs/16_13.png" height="auto" width="auto" title="caDesign"></a>
    


#### 1.3.5 è®¨è®º

* è¿ç»­åŠ¨æ€å±‚çº§å˜åŒ–ä¸‹ç”Ÿæ´»åœˆè¾¹ç•Œçš„è½å®

ä¼´éšäººå£ç»“æ„çš„æ—¥ç›Šå¤æ‚å’Œå…¬ä¼—å¯¹ç”Ÿæ´»æ ‡æ³¨çš„è¦æ±‚è¶‹é«˜ï¼Œå¯¹äºåŸå¸‚çš„ç ”ç©¶åˆ™ä»è¿‡å»å¯¹ç‰©è´¨ç©ºé—´èŒƒç•´çš„è§„åˆ’å¼€å§‹è½¬å‘å†…åœ¨çš„ç¤¾ä¼šå±æ€§ã€‚ä»¥ç”Ÿæ´»åœˆä½œä¸ºç¤¾åŒºè§„åˆ’çš„ç ”ç©¶è½½ä½“ï¼Œå¯ä»¥æ›´å¥½åœ°æ¢ç´¢ç‰©è´¨ç©ºé—´ä¸ç¤¾ä¼šå±æ€§çš„æœ‰æ•ˆå¥‘åˆï¼Œå®ç°å…¬å…±èµ„æºçš„ç²¾å‡†é…ç½®ã€‚å…³æ³¨åŸå¸‚ç”Ÿæ´»ç©ºé—´çš„æ„å»ºä¸å±…æ°‘ç”Ÿæ´»è´¨é‡çš„æå‡ï¼Œéœ€è¦åˆ†æå½“å‰æ¡ä»¶ä¸‹ååº”åŸå¸‚ç”Ÿæ´»çš„ç¤¾ä¼šç»æµåŠŸèƒ½ç©ºé—´åˆ†å¸ƒç»“æ„ï¼Œè¿™ä¸äººä»¬ç”Ÿæ´»åœ¨ç©ºé—´ä¸Šçš„å¼€å±•å³â€œäººä»¬ä¸ºäº†ç»´æŒæ—¥å¸¸ç”Ÿæ´»è€Œå‘ç”Ÿçš„è¯¸å¤šæ´»åŠ¨æ‰€æ„æˆçš„ç©ºé—´èŒƒå›´â€æ –æ¯ç›¸å…³ã€‚è¿™é‡ŒåŒ…æ‹¬è¡Œä¸šç±»åˆ«ä¸­æ‰€åŒ…æ‹¬çš„ç”Ÿæ´»æœåŠ¡ã€è´­ç‰©ã€é¥®é£Ÿã€ä¼‘é—²ã€è¿åŠ¨ã€æ•™è‚²ã€åŒ»ç–—ã€é€šå‹¤ç­‰æ‰€æœ‰å†…å®¹ã€‚è¿‘å¹´æ¥ï¼ŒåŒ—äº¬ã€ä¸Šæµ·ã€æ­å·ä¸æˆéƒ½ç­‰åŸå¸‚ç›¸ç»§æ‰“é€ 15åˆ†é’Ÿç¤¾åŒºç”Ÿæ´»åœˆä½œä¸ºåŸå¸‚ç¤¾åŒºè§„åˆ’å»ºè®¾å·¥ä½œçš„é‡è¦ç›®æ ‡ã€‚15åˆ†é’Ÿç¤¾åŒºç”Ÿæ´»åœˆæ˜¯æ‰“é€ ç¤¾åŒºç”Ÿæ´»çš„åŸºæœ¬å•å…ƒï¼Œå³åœ¨15åˆ†é’Ÿæ­¥è¡Œå¯è¾¾èŒƒå›´å†…ï¼Œé…å¤‡ç”Ÿæ´»æ‰€éœ€çš„åŸºæœ¬æœåŠ¡åŠŸèƒ½ä¸å…¬å…±æ´»åŠ¨ç©ºé—´ï¼Œå½¢æˆå®‰å…¨ã€å‹å¥½ã€èˆ’é€‚çš„ç¤¾ä¼šåŸºæœ¬ç”Ÿæ´»å¹³å°ã€‚å›½å†…ç›¸å…³ç ”ç©¶å®è·µä¸»è¦èšç„¦åœ¨ç”Ÿæ´»åœˆçš„å±‚çº§æ„å»ºã€ç¤¾åŒºç”Ÿæ´»åœˆè¾¹ç•Œçš„åˆ’å®šä¸Šå’Œç¤¾åŒºç”Ÿæ´»åœˆå…¬å…±æœåŠ¡è®¾æ–½çš„é…ç½®ä¸Šã€‚å…³äºç”Ÿæ´»åœˆçš„ç›¸å…³ç ”ç©¶ä¸­è¾ƒå¤šå°†å…¶ä½œä¸ºä¸€ç§å‘å±•ç†å¿µæŒ‡å¯¼åŸå¸‚è§„åˆ’ï¼Œå®šé‡æµ‹åº¦è¿˜ä¸å¤Ÿæ·±å…¥ã€‚

é€šå¸¸ç”Ÿæ´»åœˆçš„ç ”ç©¶æ˜¯åŸºäºæŸä½ç½®ä¸€å®šè·ç¦»ä¹‹å†…POIçš„åˆ†å¸ƒæƒ…å†µï¼Œç»“åˆè¦†ç›–ç‡ã€è¾¾æ ‡ç‡ç­‰æ–¹æ³•æ¥é‡åŒ–å’Œç ”ç©¶ç”Ÿæ´»åœˆçš„åŸå¸‚åŠŸèƒ½ç»“æ„ï¼Œä½†æ˜¯å½“è®¡ç®—å¤šä¸ªä½ç½®æˆ–è€…å¯¹å…¨åŸèŒƒå›´è¿›è¡Œè®¡ç®—ï¼Œç»“æœä¹‹é—´å¾€å¾€äº’ç›¸é‡å ã€‚åŸºäºå¤šä¸ªä½ç½®ï¼Œç”Ÿæ´»åœˆçš„é‡å æ˜¯æœ‰æ„ä¹‰çš„ï¼Œä½†æ˜¯åœ¨å®é™…çš„ç©ºé—´è§„åˆ’ä¸­ï¼Œå› ä¸ºäº’ç›¸å åˆçš„å½±å“ï¼Œåˆ™å¢åŠ äº†è½å®çš„éš¾åº¦ï¼›å½“å‰åŸºäºç”Ÿæ´»åœˆçš„ç ”ç©¶é€šå¸¸å›ºå®šè·ç¦»æ¥åˆ†æè¯¥è·ç¦»ä¸‹åŸå¸‚ç‰©è´¨ç©ºé—´å’Œç¤¾ä¼šå±æ€§çš„åˆ†å¸ƒä¸ç»“æ„ã€‚å› æ­¤å°±ä¸Šè¿°é—®é¢˜ï¼Œåœ¨è¿›ä¸€æ­¥ç”Ÿæ´»åœˆåˆ†å¸ƒå’Œç¤¾ä¼šå±æ€§ç»“æ„çš„å®šé‡åŒ–æ¢ç´¢ä¸­ï¼Œè¯•å›¾ä»¥è¿ç»­è·ç¦»èšç±»POIï¼Œè·å¾—è¿ç»­å±‚çº§çš„ç”Ÿæ´»åœˆå˜åŒ–åˆ†å¸ƒã€‚ä¸åŒå±‚çº§ä¸Šç»„å›¢çš„èŒƒå›´åæ˜ äº†ç”Ÿæ´»åœˆçš„ç©ºé—´å°ºåº¦ï¼Œèƒ½å¤Ÿæ˜ç¡®ä¸åŒå±‚çº§ä¸‹å„ä¸ªç”Ÿæ´»åœˆçš„å®é™…èŒƒå›´ã€‚å¹¶é€šè¿‡åˆ†æå±‚çº§é—´ç›¸å…³æ•°æ®åŠ¨æ€å˜åŒ–ï¼Œè·å–å…·æœ‰æ„ä¹‰çš„å…³é”®å±‚çº§ã€‚

å¯¹äºç”Ÿæ´»åœˆçš„è¡¨è¿°ï¼Œä»å¸¸è§„æ„ä¹‰ä¸Šä»¥å•ä¸ªæˆ–å¤šä¸ªæœ‰æ„ä¹‰çš„åœ°ç‚¹ä¸ºä¸­å¿ƒä¸€å®šè·ç¦»ä¸‹äººä»¬çš„æ—¥å¸¸æ´»åŠ¨ï¼ˆæˆ–POIçš„åˆ†å¸ƒï¼‰ï¼Œæ‹“å±•åˆ°ä¸åŒèšç±»è·ç¦»ä¸‹POIç‚¹çš„èšç±»åˆ†å¸ƒã€‚ä¸€æ–¹é¢ååº”äº†ç¤¾ä¼šå±æ€§çš„é›†èšè¿‡ç¨‹ï¼Œå¯ä»¥æ˜ç¡®å±‚çº§é—´çš„æ¼”åŒ–æƒ…å†µã€‚åŒæ—¶å¯¹äºç‰¹å®šå±‚çº§åŸå¸‚ç©ºé—´æ‹“å±•çš„ç ”ç©¶å…·æœ‰é‡è¦æ„ä¹‰ï¼›å¯¹äºä¸åŒå±‚çº§ï¼Œå°¤å…¶å…·æœ‰æ„ä¹‰çš„å±‚çº§ï¼Œå› ä¸ºæ˜ç¡®äº†å„ä¸ªç”Ÿæ´»åœˆçš„èŒƒå›´ï¼Œå¯ä»¥è¿›ä¸€æ­¥å‰–æä¸åŒç”Ÿæ´»åœˆä¹‹é—´çš„å…³è”ç¨‹åº¦ï¼Œä¹Ÿå¯ä»¥è¿›ä¸€æ­¥æ¢ç´¢éç”Ÿæ´»åœˆçš„ç©ºç™½åŒºåŸŸï¼ŒæŒ–æ˜åŸå¸‚ç©ºé—´æ ¼å±€å½¢æˆçš„æœºåˆ¶ã€‚

* ç”Ÿæ´»åœˆçš„ç¤¾ä¼šå±æ€§ç»“æ„

æ ¹æ®æ‰€è®¡ç®—è¡Œä¸šç±»æ‰€å±èšç±»ç°‡çš„é¢‘æ•°ï¼Œé‡‡ç”¨åæ–¹å·®é€†çŸ©é˜µå’ŒAPèšç±»ç®—æ³•è®¡ç®—ä¸åŒå±‚çº§ç”Ÿæ´»åœˆä¸åŒåŸå¸‚åŠŸèƒ½ä¹‹é—´çš„å…³è”ç¨‹åº¦ã€‚ä¸€æ–¹é¢åœ¨åŒä¸€å±‚çº§ä¸‹å¯ä»¥è§‚å¯Ÿä¸åŒç”Ÿæ´»åœˆç¤¾ä¼šç©ºé—´è‡ªç»„ç»‡ä¸‹åŸå¸‚åŠŸèƒ½ä¹‹é—´çš„é›†èšè”ç³»ç¨‹åº¦ï¼›å¦ä¸€æ–¹é¢åˆ™åœ¨è¿ç»­å±‚çº§é—´çš„å˜åŒ–ä¸­å‘ç°é›†èšå‘å±•ä¸­è¡Œä¸šç»“æ„çš„åŠ¨æ€å˜åŒ–ï¼Œä¸ºç¤¾ä¼šå¤šå…ƒéœ€æ±‚çš„æå‡ã€ä¸äººå£ç»“æ„æŒ‚é’©çš„é’ˆå¯¹æ€§è§„åˆ’æä¾›å‚è€ƒã€‚åŒæ—¶å‚è€ƒåŸå¸‚åœŸåœ°åˆ©ç”¨ç»“æ„å’Œå½¢æ€çš„å®šé‡æè¿°ç­‰ç›¸å…³ç ”ç©¶æˆæœï¼Œæ ¹æ®åŸå¸‚åœŸåœ°åˆ©ç”¨ä¿¡æ¯ç†µè®¡ç®—åŸå¸‚åœŸåœ°åˆ©ç”¨å‡è¡¡åº¦ã€‚å¯¹è¿ç»­å±‚çº§æ¯ä¸€å±‚çº§ç”Ÿæ´»åœˆå‡è¡¡åº¦è®¡ç®—ï¼Œå…¶å€¼è¶Šé«˜ï¼Œè¶Šè¶‹è¿‘äº1æ—¶ï¼Œç”Ÿæ´»åœˆæ‰€åŒ…æ‹¬çš„è¡Œä¸šç±»è¶Šå‡è¡¡ï¼Œè€Œå‡è¡¡åº¦è®¡ç®—ç»“æœä¸­è¾ƒå°å€¼çš„ç”Ÿæ´»åœˆè¯´æ˜å…·æœ‰è¾ƒä¸ºæ˜æ˜¾ä¸»å¯¼çš„åŸå¸‚åŠŸèƒ½ï¼Œå¯ä»¥é€šè¿‡è¡Œä¸šç±»åˆ«å‡ºç°çš„é¢‘æ•°åŠä¹‹é—´å…³è”ç¨‹åº¦çš„åˆ†æï¼Œè¿›ä¸€æ­¥å‘ç°ç”Ÿæ´»åœˆçš„è¡Œä¸šç±»åˆ«çš„åˆ†å¸ƒç»“æ„ã€‚åŒæ—¶ï¼Œè¿ç»­å±‚çº§çš„å˜åŒ–æ‰€åæ˜ å åˆçš„ç”Ÿæ´»åœˆä¿¡æ¯ç†µå’Œå‡è¡¡åº¦çš„å˜åŒ–ï¼Œå¯ä»¥ç¡®å®šæŸä¸€å±‚çº§ç”Ÿæ´»åœˆåœ¨å‘ä¸‹ä¸€å±‚çº§æ‰©å±•æ—¶è¡Œä¸šç±»å‡è¡¡å‘å±•æƒ…å†µï¼Œå³ç”Ÿæ´»åœˆåœ¨æ‰©å±•çš„è¿‡ç¨‹ä¸­æ–°èå…¥çš„åŒºåŸŸæ‰€åŒ…å«çš„è¡Œä¸šç±»å¯¹åŸå„è‡ªç”Ÿæ´»åœˆçš„å½±å“ã€‚

å› æ­¤ï¼Œé€šè¿‡POI æ•°æ®è¿ç»­è·ç¦»å˜åŒ–ä¸‹èšç±»ç°‡çš„åˆ†æï¼Œæ‹“å±•ç”Ÿæ´»åœˆçš„å†…æ¶µï¼Œç¡®å®šå„ä¸ªå±‚çº§ä¸‹ç”±ç¤¾ä¼šå±æ€§ç•Œå®šçš„ç”Ÿæ´»åœˆèŒƒå›´ï¼Œä»¥åŠè¿ç»­å±‚çº§æ•°æ®çš„å˜åŒ–ç‰¹å¾æ‰¾åˆ°å…·æœ‰å…³é”®æ„ä¹‰çš„å±‚çº§ï¼Œåˆ†æè¯¥å±‚çº§ä¸‹ç”Ÿæ´»åœˆçš„åˆ†å¸ƒç‰¹å¾ï¼Œå’ŒåŸºäºä¸€çº§è¡Œä¸šåˆ†ç±»çš„ä¸šæ€ç©ºé—´åˆ†å¸ƒç»“æ„ä¸å‡è¡¡åº¦æ‰€åæ˜ çš„ç”Ÿæ´»åœˆä¸šæ€åˆ†å¸ƒçš„å‡è´¨æ€§ï¼Œå®ç°å®šé‡æµ‹åº¦ï¼Œæœ‰åŠ©äºä¿ƒè¿›ç”Ÿæ´»åœˆè§„åˆ’çš„è½å®ã€‚

### 1.4 è¦ç‚¹
#### 1.4.1 æ•°æ®å¤„ç†æŠ€æœ¯

* åº”ç”¨DBSCANèšç±»ç®—æ³•å®ç°POIè·ç¦»èšç±»

* åº”ç”¨Affinity Propagationï¼ˆAPï¼‰èšç±»ç®—æ³•å®ç°ï¼ˆè¡Œä¸šåˆ†ç±»ä¸ç°‡ï¼‰åæ–¹å·®çŸ©é˜µï¼ˆåˆ—è”è¡¨ï¼‰çš„èšç±»

* ä½¿ç”¨SciPyå®ç°å¡æ–¹åˆ†å¸ƒä¸ä¼½é©¬åˆ†å¸ƒè®¡ç®—

* å»ºç«‹Sklearn çš„bunchæ•°æ®é›†

* ç”¨Kneedåº“è®¡ç®—æ‹ç‚¹

#### 1.4.2 æ–°å»ºç«‹çš„å‡½æ•°

* function - æå–åˆ†ææ‰€éœ€æ•°æ®ï¼Œå¹¶è½¬æ¢ä¸ºsklerançš„bunchå­˜å‚¨æ–¹å¼ï¼Œç»Ÿä¸€æ ¼å¼ï¼Œæ–¹ä¾¿è¯»å–. `poi_json2sklearn_bunch(fps,save_path)`

* class - ä½¿ç”¨DBSCANç®—æ³•å®ç°è¿ç»­è·ç¦»èšç±»å’Œç©ºé—´ç»“æ„åˆ†æ. `poi_spatial_distribution_structure` 

åŒ…æ‹¬ï¼š

* function - æ‰“å°æ•°ç»„é¢‘æ•°. `frequency_array(slef,array)`

* function - å•æ¬¡èšç±». `clustering_DBSCAN(self,eps_single)`

* function - æ ¹æ®èšç±»è·ç¦»åˆ—è¡¨æ‰¹é‡å¤„ç†ï¼ˆèšç±»ï¼‰. `clustering_batch_computing(self)`

* function - ä¿å­˜èšç±»ç»“æœäº.shpæ–‡ä»¶ä¸­,åŠæ‰“å°ä¸€ç»„é¢„è§ˆ. `poi2shp(self)`

* function - å¡æ–¹ç‹¬ç«‹æ€§æ£€éªŒï¼Œåˆ†æPOIä¸€çº§è¡Œä¸šåˆ†ç±»ç±»æ ‡ä¸èšç±»ç°‡çš„ç›¸å…³æ€§. `poi_chi_2Test(self)`

* unction - POIä¸€çº§è¡Œä¸šåˆ†ç±»çš„ä¸šæ€ç»“æ„. `POI_structure(self)`

---

* function - ç»˜åˆ¶æŠ˜çº¿å›¾ï¼ŒåŠå…¶æ‹ç‚¹. `kneed_lineGraph(x,y)`

* class - å›¾ç‰‡åˆå¹¶. `class combine_pics`

åŒ…æ‹¬ï¼š

* function - æ–¹æ³•ç”¨äºè¿”å›æŒ‡å®šçš„æ–‡ä»¶å¤¹åŒ…å«çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹çš„åå­—çš„åˆ—è¡¨ï¼ŒæŒ‰å­—æ¯-æ•°å­—é¡ºåºã€‚ Â·file_sorting(selfÂ·

* function - è¯»å–ä¸å‹ç¼©å›¾ç‰‡. `read_compress_imgs(self,imgs_fp)`

* function - å»ºç«‹æ–‡ä»¶å¤¹ï¼Œç”¨äºå­˜å‚¨æ‹¼åˆçš„å›¾ç‰‡. `make_dir(self)`

* function - æ‹¼åˆå›¾ç‰‡. `imgs_combination(self,imgs)`

* function - è®¡ç®—POIçš„å‡è¡¡éƒ½. `equilibriumDegree_hierarchy(poi_clustering,poi_columns,poi_label)`

#### 1.4.3 æ‰€è°ƒç”¨çš„åº“


```python
from sklearn.datasets import make_moons
from sklearn import cluster
from sklearn.preprocessing import LabelEncoder
from sklearn.datasets import base
from sklearn import covariance, manifold

import matplotlib.pyplot as plt
from matplotlib.collections import LineCollection
from PIL import Image
import numpy as np
import pandas as pd
import math

from scipy import stats
from scipy.stats import chi2
from scipy.stats import chi2_contingency

import seaborn as sns
import os,re

import json
import pickle 
import time
from tqdm import tqdm
import geopandas as gpd
from shapely.geometry import Point 
from pylab import mpl
import warnings

from data_generator import DataGenerator
from knee_locator import KneeLocator
from collections import Counter
```

#### 1.4.4 å‚è€ƒæ–‡çŒ®

1. Giuseppe Bonaccorso.Mastering Machine Learning Algorithms: Expert techniques for implementing popular machine learning algorithms, fine-tuning your models, and understanding how they work[M].Birmingham:Packt Publishing.January, 2020.
2. Timothy C.Urdan.Statistics in Plain English(ç™½è¯ç»Ÿè®¡å­¦)[M].ä¸­å›½äººæ°‘å¤§å­¦å‡ºç‰ˆç¤¾.2013,12.ç¬¬3ç‰ˆ.
3. (æ—¥)é«˜æ¡¥ ä¿¡è‘—,æ ªå¼ä¼šç¤¾TREND-PROæ¼«ç”»åˆ¶ä½œï¼Œé™ˆåˆšè¯‘.æ¼«ç”»ç»Ÿè®¡å­¦[M].ç§‘å­¦å‡ºç‰ˆç¤¾.åŒ—äº¬.
4. Dawn Griffiths.Head First Statistics: A Brain-Friendly Guide[M].Sebastopol:O'Reilly Media.September, 2008
